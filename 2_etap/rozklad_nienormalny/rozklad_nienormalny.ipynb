{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WyfIaktxaD3"
   },
   "source": [
    "# Rozkład Nienormalny\n",
    "\n",
    "![robot.png](https://live.staticflickr.com/65535/54430891765_38ef5cb61e_z.jpg)\n",
    "\n",
    "*Obraz wygenrowany za pomocą ChatGPT.*\n",
    "\n",
    "## Wstęp\n",
    "\n",
    "Szum towarzyszy nam przynajmniej tak długo, jak długo rejestrujemy obserwacje wszelkiego rodzaju. Czy wynika to z faktu, że nie żyjemy w świecie klasycznych filozoficznych abstrakcji, czy może prawda jest o wiele bardziej prozaiczna—w kadr aparatu, obiektyw teleskopu, urywek tekstu czy nagranie dźwiękowe bardzo często dostają się zupełnie przez nas niepożądane sygnały, które—owszem—współtworzą rzeczywistość, lecz w momencie przeprowadzenia obserwacji wolelibyśmy ich uniknąć. W kontekście tego zadania, taką nadmiarową informację nałożoną na informację bazową (prawdziwą), będziemy nazywać szumem.\n",
    "\n",
    "Szum rozważa się, a więc i opisuje matematycznie—w naukach ścisłych, szczególnie w tzw. *teorii informacji*. W grafice komputerowej szumem (*funkcją zaszumiającą*) nazwiemy f:\n",
    "\n",
    "$$f: X → X$$\n",
    "\n",
    "gdzie X to określona dziedzina zdjęć. Dla zdjęć o rozmiarze 28x28 w skali szarości zakodowanej w zakresie liczb rzeczywistych [0, 1]:\n",
    "\n",
    "$$X = [0,1]^{28 * 28} $$\n",
    "\n",
    "Sensownym założeniem jest, że f istotnie różni się od funkcji identycznościowej, tj. w istotny sposób zniekształca bazowe zdjęcie.\n",
    "\n",
    "*Szum gaussowski* definiuje się na podstawie **rozkładu Gaussa**, o gęstości prawdopowodobieństwa zadanej wzorem:\n",
    "\n",
    "$$f_{\\mu, \\sigma}(x) = \\frac{1}{\\sigma \\sqrt{2π}}e^{\\frac{-(x - \\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "**Rozkład Gaussa** jest parametryzowany przez dwie stałe: $\\mu$ - *średnią* i $\\sigma$ - *odchylenie standardowe* lub równoważnie: $\\mu$ - *średnią* i $\\sigma^2$ - *wariancję* (kwadrat odchylenia standardowego). Popularne biblioteki do obliczeń zawierają implementację *samplowania* próbek z tego rozkładu. By zaszumić obraz parametryzowanym rozkładem, próbkujemy z niego tablicę o rozmiarze równym rozmiarowi zdjęcia, dodajemy szum do zdjęcia (dodajemy *po pikselach*), po czym zapewniamy, by wartości pikseli pozostały w przedziale [0, 1] (funkcja **clamp**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehc9GC7txzKn"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "def add_normal_noise(image, mean=0, std=0.2):\n",
    "    \"\"\"Adds normal (Gaussian) noise to the image.\"\"\"\n",
    "    noise = torch.distributions.normal.Normal(mean, std)\n",
    "    noise = noise.sample(image.size())\n",
    "    noisy_image = image + noise\n",
    "    return torch.clamp(noisy_image, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yg_SzGQbx3CK"
   },
   "source": [
    "**Rozkład jednostajny** ma prostą intuicję—określamy przedział $[a,b]$ i chcemy, by szanse wylosowania dowolnych dwóch różnych liczb z przedziału były takie same, natomiast dowolnej liczby spoza przedziału—zerowe. Formalnie, gęstość prawdopodobieństwa rozkładu jednostajnego określa wzór:\n",
    "\n",
    "$$    \n",
    "  f(x) =\n",
    "  \\begin{cases}\n",
    "    \\frac{1}{b-a}, & \\text{for } a \\leq x \\leq b \\\\\n",
    "    0\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "Zaszumiając obrazek szumem jednostajnym, postępujemy analogicznie jak przy szumie gaussowskim. Losujemy próbkę z rozkładu, dodajemy ją do zdjęcia i ewentualne piksele wykraczające poza przedział $[0,1]$ ustawiamy na odpowiednie ograniczenie zakresu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-D8V7DUx8UK"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "def add_uniform_noise(image, low=-0.5, high=0.5):\n",
    "    \"\"\"Adds uniform noise to the image.\"\"\"\n",
    "    noise = torch.empty(image.size()).uniform_(low, high)\n",
    "    noisy_image = image + noise\n",
    "    return torch.clamp(noisy_image, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnyPrLrlyG8x"
   },
   "source": [
    "## Zadanie\n",
    "\n",
    "Wyobraź sobie, że jesteś specjalistą ds. przetwarzania obrazu w firmie zajmującej się analizą i rekonstrukcją obrazów. Twój zespół pracuje nad systemem, który potrafi nie tylko usuwać szum z obrazów, ale również identyfikować jego rodzaj i parametry, co może dostarczyć cennych informacji o źródle zakłóceń.\n",
    "\n",
    "Twoim zadaniem jest zaprojektowanie i wytrenowanie pojedynczej architektury sieci neuronowej, która będzie w stanie jednocześnie realizować trzy cele:\n",
    "\n",
    "- **Odszumianie obrazów** - przywracanie oryginalnego wyglądu zdjęć zaszumionych jednym z dwóch rodzajów szumów: gaussowskim albo jednostajnym;\n",
    "- **Klasyfikacja typu szumu** - określenie, czy zdjęcie zostało zaszumione szumem gaussowskim (etykieta 0) czy jednostajnym (etykieta 1);\n",
    "- **Estymacja parametrów szumu gaussowskiego** - dla zdjęć zaszumionych szumem gaussowskim, model powinien dodatkowo estymować parametry tego szumu: średnią $\\mu$ i odchylenie standardowe $\\sigma$\n",
    "\n",
    "**Zwróć uwagę, że każde poszczególne zdjęcie zostało zaszumione losowo wybranym rozkładem z losowo wybranymi (potencjalnie różnymi na całym zbiorze danych) parametrami.**\n",
    "\n",
    "### Dane\n",
    "Dostępne dla Ciebie w tym zadaniu dane to:\n",
    "\n",
    "- **Zbiór danych treningowych**, zawierający zarówno obrazy oryginalne, jak i ich zaszumione wersje wraz z etykietami rodzaju szumu\n",
    "- **Zbiór danych walidacyjnych**, który pomoże Ci ocenić jakość Twojego modelu w trakcie treningu\n",
    "\n",
    "Przygotowaliśmy dla Ciebie dataloader. W zbiorze treningowym, każdy przykład składa się z:\n",
    "\n",
    "- Zdjęcia przed zaszumieniem - klucz `['original']`\n",
    "- Zdjęcia po zaszumieniu - klucz `['noised']`\n",
    "- Etykiety rodzaju szumu - klucz `['label']`\n",
    "- Parametrów szumu - klucz `['params']` (dostępne tylko dla zbioru walidacyjnego i testowego)\n",
    "\n",
    "Poniższa grafika ilustruje przykładowy proces powstawania zaszumionych zdjęć dla obu szumów parametryzowanych przykładowymi argumentami.\n",
    "\n",
    "![noise_schema.png](https://live.staticflickr.com/65535/54429663172_1014ff20d7_z.jpg\")\n",
    "\n",
    "Twoje rozwiązanie zostanie ostatecznie przetestowane na Platformie Konkursowej na ukrytym zestawie danych testowych, który jest zbalansowany pod względem typów szumów, a obrazki w nim cechują się takimi samymi charakterystykami, jak te dostarczone uczestnikom.\n",
    "\n",
    "\n",
    "### Kryterium Oceny\n",
    "\n",
    "Jak możesz się spodziewać, w ewaluacji będziemy oceniać cztery kluczowe aspekty Twojego rozwiązania:\n",
    "\n",
    "1. **Dokładność klasyfikacji binarnej szumu** (waga 25%) - jak skutecznie model rozpoznaje rodzaj szumu:\n",
    "\n",
    "$$    \n",
    "  accuracyScore =\n",
    "  \\begin{cases}\n",
    "    \\frac{accuracy - 0.5}{0.45}, & \\text{dla } 0.5 < accuracy < 0.95 \\\\\n",
    "    0.0, & \\text{dla } accuracy \\leq 0.5 \\\\\n",
    "    1.0, & \\text{dla } 0.95 \\leq accuracy\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "2. **Jakość rekonstrukcji obrazu** (waga 25%) - mierzona metryką PSNR (Peak Signal-to-Noise Ratio):\n",
    "\n",
    "$$    \n",
    "  psnrScore =\n",
    "  \\begin{cases}\n",
    "    \\frac{PSNR - 10}{6}, & \\text{dla } 10 < PSNR < 16 \\\\\n",
    "    0.0, & \\text{dla } PSNR \\leq 10 \\\\\n",
    "    1.0, & \\text{dla } 16 \\leq PSNR\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "gdzie PSNR jest zdefiniowane jako:\n",
    "\n",
    "$$PSNR = 10 log_{10}\\frac{MAX_{I}^{2}}{MSE},$$\n",
    "\n",
    "gdzie $MAX_{I}$ to maksymalna możliwa wartość piksela przy zadanej reprezentacji i w naszym przypadku $MAX_{I} = 1$.\n",
    "\n",
    "\n",
    "3. **Dokładność estymacji parametru średniej $\\mu$ szumu gaussowskiego** (waga 25%) - mierzona błędem średniokwadratowym (MSE) i liczona po elementach zbioru testowego z etykietą 0 (szum *gaussowski*):\n",
    "\n",
    "$$    \n",
    "  meanMseScore =\n",
    "  \\begin{cases}\n",
    "   1.0, & \\text{dla } MSE < 0.005 \\\\\n",
    "   0.0, & \\text {w przeciwnym przypadku}\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "4. **Dokładność estymacji parametru odchylenia standardowego $\\sigma$ szumu gaussowskiego** (waga 25%) - również mierzona błędem średniokwadratowym (MSE) i liczona po elementach zbioru testowego z etykietą 0 (szum *gaussowski*):\n",
    "\n",
    "$$    \n",
    "  stdMseScore =\n",
    "  \\begin{cases}\n",
    "   1.0, & \\text{dla } MSE < 0.005 \\\\\n",
    "   0.0, & \\text {w przeciwnym przypadku}\n",
    "  \\end{cases}\n",
    "\\\n",
    "$$\n",
    "\n",
    "**Ostateczna Formuła Oceny**\n",
    "\n",
    "Końcowa ocena jest ważoną sumą powyższych metryk zgodnie ze wzorem:\n",
    "$$ finalScore = 25 \\cdot accuracyScore + 25 \\cdot psnrScore + 25 \\cdot meanMseScore + 25 \\cdot stdMseScore $$\n",
    "\n",
    "Za to zadanie możesz zdobyć od 0 do 100 punktów, gdzie:\n",
    "\n",
    "- Wartości bliskie 0 wskazują na słabe rozwiązanie;\n",
    "- Wartości bliskie 100 wskazują na doskonałe rozwiązanie, które skutecznie klasyfikuje rodzaj szumu, rekonstruuje oryginalne obrazy i precyzyjnie estymuje parametry szumu gaussowskiego.\n",
    "\n",
    "## Ograniczenia\n",
    "\n",
    "- Do uczenia modelu możesz używać jedynie zbioru treningowego.\n",
    "- Twoje rozwiazanie będzie testowane na Platformie Konkursowej bez dostępu do internetu oraz w środowisku z GPU.\n",
    "- Ewaluacja Twojego finalnego rozwiązania na Platformie Konkursowej nie może trwać dłużej niż 5 minut z GPU.\n",
    "\n",
    "## Pliki zgłoszeniowe\n",
    "\n",
    "Ten notebook uzupełniony o Twoje rozwiązanie (patrz klasa `Model`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CoefBVS4NON"
   },
   "source": [
    "# Kod Startowy\n",
    "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8S0JTiGmOjMW"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # Podczas sprawdzania ustawimy tą flagę na True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E16NAlY1wppa",
    "outputId": "abc952d7-ef34-4c63-b3da-c44cf1471829"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "from collections.abc import Callable\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA niedostępna!\"\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gh58zFMKOxId"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "seed = 42\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wekRmN6dWjw0"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "# Komórka zawierająca funkcje pomocnicze do wizualiacji wyników\n",
    "\n",
    "def plot_samples(dataset: Dataset, num_images: int = 6, title: str = \"\") -> None:\n",
    "    \"\"\"\n",
    "    Funkcja do wyświetlania przykładów obrazów oryginalnych oraz zaszumionych\n",
    "\n",
    "    Przyjmuje:\n",
    "        dataset (Dataset): Zbiór danych.\n",
    "        num_images (int): Liczba obrazów do wyświetlenia.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, num_images, figsize=(2 * num_images, 4))\n",
    "    fig.suptitle(title, fontsize=10)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        sample = dataset[i]\n",
    "        original_image = sample[\"original\"]\n",
    "        noised_image = sample[\"noised\"]\n",
    "        label = sample[\"label\"]\n",
    "        params = sample.get(\"params\", None)\n",
    "\n",
    "        column_title = f\"Przykład {i+1}\\nEtykieta: {label.item():.0f}\"\n",
    "\n",
    "        if params is not None:\n",
    "            if label.item() == 0:\n",
    "                column_title += f\"\\nμ: {params[0].item():.2f}\\nσ: {params[1].item():.2f}\"\n",
    "            else:\n",
    "                column_title += f\"\\nlow: {params[0].item():.2f}\\nhigh: {params[1].item():.2f}\"\n",
    "        else:\n",
    "            if label.item() == 0:\n",
    "                column_title += \"\\nμ: Brak\\nσ: Brak\"\n",
    "            else:\n",
    "                column_title += \"\\nlow: Brak\\nhigh: Brak\"\n",
    "\n",
    "        column_title += \"\\n\\nOryginalny\"\n",
    "\n",
    "        axs[0, i].set_title(column_title, fontsize=8, pad=5)\n",
    "        axs[0, i].imshow(original_image.squeeze(), cmap=\"gray\")\n",
    "        axs[0, i].axis(\"off\")\n",
    "\n",
    "        axs[1, i].set_title(\"Zaszumiony\", fontsize=8, pad=5)\n",
    "        axs[1, i].imshow(noised_image.squeeze(), cmap=\"gray\")\n",
    "        axs[1, i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_results(model: nn.Module, examples: Dict, num_images: int = 6) -> None:\n",
    "    \"\"\"\n",
    "    Funkcja do wyświetlania przykładów obrazu zaszumionego oraz odszumionego przez model\n",
    "\n",
    "    Przyjmuje:\n",
    "        model (nn.Module): Model do odszumiania obrazów.\n",
    "        examples (dict): Słownik zawierający przykłady obrazów.\n",
    "        num_images (int): Liczba obrazów do wyświetlenia.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    noisy_images = examples[\"noised\"][:num_images].to(DEVICE)\n",
    "    clean_images = examples[\"original\"][:num_images]\n",
    "    label = examples[\"label\"][:num_images]\n",
    "    params = examples[\"params\"][:num_images]\n",
    "    mean_real = params[:, 0].view(-1, 1)\n",
    "    std_real = params[:, 1].view(-1, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_images, predictions, mean_pred, std_pred = model(noisy_images.to(DEVICE))\n",
    "\n",
    "    fig, axs = plt.subplots(3, num_images, figsize=(2 * num_images, 6))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        column_title = (\n",
    "            f\"Przykład {i+1}\\n\"\n",
    "            f\"Etykieta: {float(predictions[i].item() > 0.5):.0f}/{label[i].item():.0f}\\n\"\n",
    "        )\n",
    "\n",
    "        if label[i].item() == 0:\n",
    "            column_title += (\n",
    "                f\"μ: {mean_pred[i].item():.2f}/{mean_real[i].item():.2f}\\n\"\n",
    "                f\"σ: {std_pred[i].item():.2f}/{std_real[i].item():.2f}\\n\"\n",
    "            )\n",
    "        else:\n",
    "            column_title += \"\\n\\n\"\n",
    "\n",
    "        column_title += \"\\nZaszumiony\"\n",
    "\n",
    "        axs[0, i].set_title(column_title, fontsize=8, pad=5)\n",
    "        axs[0, i].imshow(noisy_images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "        axs[0, i].axis(\"off\")\n",
    "\n",
    "        axs[1, i].set_title(\"Odszumiony\", fontsize=8, pad=5)\n",
    "        axs[1, i].imshow(output_images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "        axs[1, i].axis(\"off\")\n",
    "\n",
    "        axs[2, i].set_title(\"Oryginalny\", fontsize=8, pad=5)\n",
    "        axs[2, i].imshow(clean_images[i].squeeze(), cmap=\"gray\")\n",
    "        axs[2, i].axis(\"off\")\n",
    "\n",
    "    fig.text(0.5, 0.01, \"Format: Predykcja/Etykieta\", ha='center', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85, bottom=0.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAcEJUUx4DtP"
   },
   "source": [
    "## Ładowanie Danych\n",
    "Za pomocą poniższego kodu dane zostaną wczytane i odpowiednio przygotowane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPzt_BmNwppo"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "# Komórka zawierająca funkcje pomocnicze do przygotowania danych.\n",
    "\n",
    "class NoisedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Zbiór danych wczytywany z pliku pickle.\n",
    "\n",
    "    Przyjmuje:\n",
    "        file_path (str): Ścieżka do pliku pickle zawierającego dane.\n",
    "        transform (callable, opcjonalnie): Transformacje stosowane do obrazów i etykiet.\n",
    "    \"\"\"\n",
    "    def __init__(self, pickle_file, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "\n",
    "        self.has_params = 'params' in self.data[0]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:\n",
    "        sample = self.data[idx]\n",
    "        original_image = sample['original']\n",
    "        noised_image = sample['noised']\n",
    "        label = sample['label']\n",
    "\n",
    "        if self.has_params:\n",
    "            data = {'params': sample['params']}\n",
    "        else:\n",
    "            data = {}\n",
    "\n",
    "        if self.transform:\n",
    "            original_image = self.transform(original_image)\n",
    "            noised_image = self.transform(noised_image)\n",
    "\n",
    "        data.update({\n",
    "            'original': original_image,\n",
    "            'noised': noised_image,\n",
    "            'label': label\n",
    "        })\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "def setup_data(\n",
    "        train_transform: Callable | None = None,\n",
    "        val_transform: Callable | None = None,\n",
    "        root: str = './'\n",
    "    ) -> Tuple[Dataset, Dataset]:\n",
    "    \"\"\"\n",
    "    Przygotowuje zbiory danych do trenowania i walidacji, pobierając je jeśli to konieczne.\n",
    "\n",
    "    Przyjmuje:\n",
    "        train_transform (callable, opcjonalnie): Augmentacje dla zbioru treningowego.\n",
    "        val_transform (callable, opcjonalnie): Augmentacje dla zbioru walidacyjnego.\n",
    "        root (str, opcjonalnie): Katalog bazowy dla plików z danymi.\n",
    "\n",
    "    Zwraca:\n",
    "        tuple: Zbiory danych (train_ds, val_ds).\n",
    "    \"\"\"\n",
    "    if train_transform is None:\n",
    "        train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    if val_transform is None:\n",
    "        val_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_file = root+'train.pkl'\n",
    "    val_file = root+'val.pkl'\n",
    "\n",
    "    if not os.path.exists(root):\n",
    "        os.makedirs(root)\n",
    "\n",
    "    train_ds = NoisedDataset(train_file, transform=train_transform)\n",
    "    val_ds = NoisedDataset(val_file, transform=val_transform)\n",
    "\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "id": "jMWaF0ujRCOy",
    "outputId": "0ffac6b7-bf83-43a7-9e1f-858c3bc4a2b8"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "train_ds, val_ds = setup_data(root=\"./\")\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    print(\"Liczba zdjęć w zbiorze treningowym:\", len(train_ds), \", liczba zdjęć w zbiorze walidacyjnym:\", len(val_ds))\n",
    "    plot_samples(train_ds, num_images=6, title=\"Zbiór treningowy\")\n",
    "    plot_samples(val_ds, num_images=6, title=\"Zbiór walidacyjny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6z4kilVS31sA"
   },
   "source": [
    "## Kod z Kryterium Oceniającym\n",
    "Kod, zbliżony do poniższego, będzie używany do oceny rozwiązania na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXPJGwkOe9b9"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "# Komórka zawierająca funkcje pomocnicze do obliczenia wartości metryk modelu\n",
    "\n",
    "def compute_psnr(input_image: torch.Tensor, target_image: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Funkcja obliczająca PSNR pomiędzy dwoma obrazami.\n",
    "\n",
    "    Przyjmuje:\n",
    "        input_image (torch.Tensor): Pierwszy obraz.\n",
    "        target_image (torch.Tensor): Drugi obraz.\n",
    "\n",
    "    Zwraca:\n",
    "        torch.Tensor: Wartość PSNR.\n",
    "    \"\"\"\n",
    "    mse = F.mse_loss(input_image, target_image)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    return 10 * torch.log10(1 / mse)\n",
    "\n",
    "def model_eval(model: nn.Module, dataloader: DataLoader, device: str = DEVICE) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\"\n",
    "    Funkcja do ewaluacji modelu na zbiorze danych.\n",
    "\n",
    "    Przyjmuje:\n",
    "        model (nn.Module): Model do ewaluacji.\n",
    "        dataloader (DataLoader): DataLoader z danymi do ewaluacji.\n",
    "        device (str, opcjonalnie): Urządzenie, na którym ma być przeprowadzona ewaluacja.\n",
    "\n",
    "    Zwraca:\n",
    "        tuple: Krotka zawierająca wartości metryk (PSNR, dokładność, MSE dla parametru 1, MSE dla parametru 2).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Inicjalizacja zmiennych do przechowywania wyników\n",
    "    psnr = 0\n",
    "    correct = 0\n",
    "    mean_mse = 0\n",
    "    std_mse = 0\n",
    "\n",
    "    total_samples = 0\n",
    "    total_label0_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            noised_images = data[\"noised\"].to(device)\n",
    "            original_images = data[\"original\"].to(device)\n",
    "            labels = data[\"label\"].to(device)\n",
    "            params = data[\"params\"].to(device)\n",
    "            batch_size = len(labels)\n",
    "\n",
    "            mean_real = params[:, 0].view(-1, 1)\n",
    "            std_real = params[:, 1].view(-1, 1)\n",
    "\n",
    "            output_images, labels_pred, mean_pred, std_pred = model(noised_images)\n",
    "\n",
    "            # Obliczanie dokładności klasyfikacji\n",
    "            correct += ((labels_pred >= 0.5).float().view(-1) == labels).sum().item()\n",
    "\n",
    "            # Obliczanie PSNR\n",
    "            psnr += compute_psnr(output_images, original_images) * batch_size\n",
    "\n",
    "            # Obliczanie MSE dla parametrów, gdy etykieta wynosi 0\n",
    "            label0_mask = (labels == 0)\n",
    "            num_label0 = label0_mask.sum().item()\n",
    "\n",
    "            if num_label0 > 0:\n",
    "                mean_mse += F.mse_loss(mean_pred[label0_mask], mean_real[label0_mask], reduction='sum')\n",
    "                std_mse += F.mse_loss(std_pred[label0_mask], std_real[label0_mask], reduction='sum')\n",
    "\n",
    "            total_samples += batch_size\n",
    "            total_label0_samples += num_label0\n",
    "\n",
    "    # Obliczanie średnich wartości metryk\n",
    "    psnr /= total_samples\n",
    "    accuracy = correct / total_samples\n",
    "    mean_mse /= total_label0_samples\n",
    "    std_mse /= total_label0_samples\n",
    "\n",
    "    return psnr.item(), accuracy, mean_mse.item(), std_mse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Hfj5TwGwppv"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "# Komórka zawierająca funkcje pomocnicze do oceniania Twojego rozwiązania\n",
    "\n",
    "def calculate_score(\n",
    "    psnr: float, accuracy: float, mean_mse: float, std_mse: float\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Funkcja obliczająca punkty za zadanie na podstawie metryk modelu.\n",
    "\n",
    "    Przyjmuje:\n",
    "        psnr (float): Wartość PSNR.\n",
    "        accuracy (float): Dokładność klasyfikacji.\n",
    "        mean_mse (float): MSE dla parametru 1.\n",
    "        std_mse (float): MSE dla parametru 2.\n",
    "\n",
    "    Zwraca:\n",
    "        tuple: Krotka zawierająca punkty za zadanie (PSNR, dokładność, MSE dla parametru 1, MSE dla parametru 2).\n",
    "    \"\"\"\n",
    "\n",
    "    def scale(x, lower=0.0, upper=1.0, max_points=1.0):\n",
    "        scaled = min(max(x, lower), upper)\n",
    "        return (scaled - lower) / (upper - lower) * max_points\n",
    "\n",
    "    accuracy_score = scale(accuracy, lower=0.5, upper=0.95)\n",
    "    psnr_score = scale(psnr, lower=10.0, upper=16.0)\n",
    "\n",
    "    mean_score = 0.0\n",
    "    if mean_mse < 0.005:\n",
    "        mean_score = 1.0\n",
    "\n",
    "    std_score = 0.0\n",
    "    if std_mse < 0.005:\n",
    "        std_score = 1.0\n",
    "\n",
    "    return psnr_score, accuracy_score, mean_score, std_score\n",
    "\n",
    "\n",
    "def grade_solution(model: nn.Module, dataloader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Funkcja oceniająca model na zbiorze walidacyjnym.\n",
    "\n",
    "    Przyjmuje:\n",
    "        model (nn.Module): Model do oceny.\n",
    "        dataloader (DataLoader): DataLoader z danymi do oceny.\n",
    "\n",
    "    Zwraca:\n",
    "        float: Liczba punktów za zadanie.\n",
    "    \"\"\"\n",
    "    psnr, accuracy, mean_mse, std_mse = model_eval(model, dataloader)\n",
    "    psnr_score, accuracy_score, mean_score, std_score = calculate_score(\n",
    "        psnr, accuracy, mean_mse, std_mse\n",
    "    )\n",
    "    score = round(\n",
    "        psnr_score * 25 + accuracy_score * 25 + mean_score * 25 + std_score * 25\n",
    "    )\n",
    "\n",
    "    # Zaokrąglenie do liczby całkowitej, przedział [0, 100]\n",
    "    score = round(score)\n",
    "\n",
    "    print(\n",
    "        f\"Metryki na zbiorze walidacyjnym\\n\"\n",
    "        f\"psnr: {psnr:.2f}, accuracy: {accuracy:.2f}, mean_mse: {mean_mse:.6f}, std_mse: {std_mse:.6f}\\n\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Punkty częściowe za zadanie\\n\"\n",
    "        f\"psnr: {(psnr_score * 25):.2f}, accuracy: {(accuracy_score * 25):.2f}, mean_mse: {(mean_score * 25):.2f}, std_mse: {(std_score * 25):.2f}\\n\"\n",
    "    )\n",
    "    print(f\"Estymowana liczba punktów za zadanie: {score}\")\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSbmLdsCnNsQ"
   },
   "source": [
    "# Twoje Rozwiązanie\n",
    "W tej sekcji należy umieścić Twoje rozwiązanie. Wprowadzaj zmiany wyłącznie tutaj!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCZcdggpi4Lk"
   },
   "outputs": [],
   "source": [
    "# definicje augmentacji dla zbioru treningowego i walidacyjnego. Domyślnie None oznacza brak augmentacji\n",
    "train_transform = None\n",
    "val_transform = None\n",
    "\n",
    "# rozmiar batcha\n",
    "BATCH_SIZE: int = 64\n",
    "\n",
    "train_ds, val_ds = setup_data(train_transform, val_transform, root=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CiKGndLFwppq",
    "outputId": "5b5dfa23-474c-445f-bf77-5e7bbcc3797d"
   },
   "outputs": [],
   "source": [
    "# tutaj stwórz i wytrenuj Twój model\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Przekształcenie przeprowadzane przez model.\n",
    "\n",
    "        Przyjmuje:\n",
    "            x (torch.Tensor): Obraz wejściowy [B, 1, H, W].\n",
    "\n",
    "        Zwraca:\n",
    "            Wynik zwracany w postaci krotki:\n",
    "            torch.Tensor: Obraz wyjściowy [B, 1, H, W].\n",
    "            torch.Tensor: Predykcje klasyfikacji [B, 1].\n",
    "            torch.Tensor: Parametr 1 [B, 1].\n",
    "            torch.Tensor: Parametr 2 [B, 1].\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        return (\n",
    "            torch.rand_like(x, device=device),\n",
    "            torch.rand(x.shape[0], 1, device=device),\n",
    "            torch.randn(x.shape[0], 1, device=device),\n",
    "            torch.randn(x.shape[0], 1, device=device)\n",
    "        )\n",
    "\n",
    "\n",
    "def train_model() -> Model:\n",
    "    \"\"\"Stwórz i wytrenuj model\"\"\"\n",
    "    return Model().to(DEVICE)\n",
    "\n",
    "\n",
    "your_model = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPmZzsWA3rZO"
   },
   "source": [
    "# Ewaluacja\n",
    "Uruchomienie poniższej komórki pozwoli sprawdzić, ile punktów zdobyłoby Twoje rozwiązanie na danych walidacyjnych. Przed wysłaniem upewnij się, że cały notebook wykonuje się od początku do końca bez błędów i bez konieczności ingerencji użytkownika po wybraniu opcji \"Run All\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0LrjOyGj0Bj"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "val_dataloader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    grade_solution(your_model, val_dataloader)\n",
    "    examples = next(iter(val_dataloader))\n",
    "    plot_results(your_model, examples, num_images=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8u2CnBEToFtC"
   },
   "source": [
    "Podczas sprawdzania model zostanie zapisany jako `your_model.pkl` i oceniony na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkFHMWnbjnd5"
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "if FINAL_EVALUATION_MODE:\n",
    "    import cloudpickle\n",
    "\n",
    "    # Gdy model posiada parametry, ustaw go w trybie ewaluacji i przenieś na CPU\n",
    "    if list(your_model.parameters()):\n",
    "        your_model.eval()\n",
    "        your_model.cpu()\n",
    "\n",
    "    OUTPUT_PATH = \"file_output\"\n",
    "    FUNCTION_FILENAME = \"your_model.pkl\"\n",
    "    FUNCTION_OUTPUT_PATH = os.path.join(OUTPUT_PATH, FUNCTION_FILENAME)\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "    with open(FUNCTION_OUTPUT_PATH, \"wb\") as f:\n",
    "        cloudpickle.dump(your_model, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

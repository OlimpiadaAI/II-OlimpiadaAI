{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8542bc",
   "metadata": {},
   "source": [
    "# Prototypy Danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf54003",
   "metadata": {},
   "source": [
    "![Prototyping Data](https://live.staticflickr.com/65535/54547003811_0b48d94df0_b.jpg)\n",
    "\n",
    "*Grafika wygenerowana przez Sora - ChatGPT.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0545e",
   "metadata": {},
   "source": [
    "## WstÄ™p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e84e5f",
   "metadata": {},
   "source": [
    "Modele uczenia maszynowego mogÄ… analizowaÄ‡ skomplikowane dane wejÅ›ciowe takie jak obrazy, tekst po przeksztaÅ‚ceniu ich do wielowymiarowych reprezentacji zwanych zanurzeniami (ang. *embeddings*). W takiej przestrzeni wielowymiarowej obiekty o zbliÅ¼onych cechach umieszczane sÄ… blisko siebie, co umoÅ¼liwia modelom skuteczne analizowanie relacji i podobieÅ„stw miÄ™dzy nimi oraz podejmowanie trafnych decyzji.\n",
    "\n",
    "Trenowanie coraz bardziej nowoczesnych i wiÄ™kszych modeli wymaga zwiÄ™kszonej liczby danych, co wiÄ…Å¼e siÄ™ ze zwiÄ™kszonym zapotrzebowaniem na zasoby â€“ zarÃ³wno pamiÄ™Ä‡, jak i moc obliczeniowÄ…. Aby ograniczyÄ‡ te koszty, poszukuje siÄ™ metod umoÅ¼liwiajÄ…cych redukcjÄ™ danych przy zachowaniu ich informacyjnej wartoÅ›ci. W takich przypadkach celem jest wiÄ™c stworzenie mniejszego zbioru danych, ktÃ³ry pozwoli na wytrenowanie modelu o podobnej jakoÅ›ci co na oryginalnych danych. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abbf015",
   "metadata": {},
   "source": [
    "## Zadanie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05975d44",
   "metadata": {},
   "source": [
    "To zadanie stanowi modyfikacjÄ™ podejÅ›cia opisanego we wstÄ™pie. Twoim zadaniem bÄ™dzie wyznaczenie maÅ‚ego zbioru na podstawie dostarczonego zbioru treningowego i dostarczonego klasyfikatora. Elementy z nowo utworzonego zbioru bÄ™dziemy nazywaÄ‡ prototypami. Co waÅ¼ne, Twoim zadaniem jest stworzenie zbioru 150 zanurzeÅ„ (prototypÃ³w) na podstawie reprezentacji z ostatniej warstwy sieci *Net()*. Oznacza to, Å¼e dla kaÅ¼dego obrazka ze zbioru testowego zostanie przypisane jego wyjÅ›cie z ostatniej warstwy sieci *Net()* (zanurzenie)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d2665",
   "metadata": {},
   "source": [
    "### Ewaluacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35db7c",
   "metadata": {},
   "source": [
    "KaÅ¼dej prÃ³bce ze zbioru testowego zostanie przypisana klasa prototypu, ktÃ³ry znajduje siÄ™ najbliÅ¼ej (w sensie metryki euklidesowej) w przestrzeni zanurzeÅ„ (algorytm one-nearest-neighbor). Ocenie podlegaÄ‡ bÄ™dzie poprawnoÅ›Ä‡ klasyfikacji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716f539",
   "metadata": {},
   "source": [
    "### Kryterium Oceny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e362b5f",
   "metadata": {},
   "source": [
    "Za to zadanie moÅ¼esz zdobyÄ‡ pomiÄ™dzy 0 a 100 punktÃ³w.\n",
    "Twoje rozwiÄ…zanie bÄ™dzie oceniane na podstawie dokÅ‚adnoÅ›ci klasyfikacji (*acc*) uzyskanej na tajnym zbiorze testowym.\n",
    "\n",
    "Liczba punktÃ³w, jakÄ… otrzymasz, bÄ™dzie liczona wedÅ‚ug wzoru: \n",
    "$$\n",
    "\\text{punkty} =\n",
    "\\begin{cases}\n",
    "0 & \\text{gdy } acc \\leq 0.40 \\\\\n",
    "100 \\cdot \\frac{acc - 0.4}{0.68-0.40} & \\text{gdy } 0.40 < acc < 0.68 \\\\\n",
    "100 & \\text{gdy } acc \\geq 0.68 \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8ee09",
   "metadata": {},
   "source": [
    "### Ograniczenia\n",
    "- Do utworzenia zbioru prototypÃ³w moÅ¼esz wykorzystaÄ‡ zanurzenia zbioru zdjÄ™Ä‡ ze zbioru treningowego (`train_embeddings`), oraz etykiet klas dla tego zbioru `train_labels`.\n",
    "- Twoje rozwiÄ…zanie bÄ™dzie testowane na Platformie Konkursowej bez dostÄ™pu do internetu oraz w Å›rodowisku z GPU.\n",
    "- Ewaluacja Twojego finalnego rozwiÄ…zania na Platformie Konkursowej nie moÅ¼e trwaÄ‡ dÅ‚uÅ¼ej niÅ¼ 5 minut z GPU.\n",
    "- MoÅ¼esz uÅ¼ywaÄ‡ nastÄ™pujÄ…cych bibliotek:\n",
    "    - `random`\n",
    "    - `numpy`\n",
    "    - `math`\n",
    "    - `torch`\n",
    "    - `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8a186",
   "metadata": {},
   "source": [
    "## Pliki zgÅ‚oszeniowe\n",
    "Ten notebook uzupeÅ‚niony o Twoje rozwiÄ…zanie zawierajÄ…ce implementacje klasy `YourSolution`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b27fba",
   "metadata": {},
   "source": [
    "# Kod Startowy\n",
    "W tej sekcji inicjalizujemy Å›rodowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod uÅ‚atwi Tobie efektywne operowanie na danych i budowanie wÅ‚aÅ›ciwego rozwiÄ…zania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27803caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # Podczas sprawdzania ustawimy tÄ… flagÄ™ na True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac39f46-ecd9-444c-a32a-fc62a1b776d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "# PoniÅ¼ej zaimportowane sÄ… biblioteki potrzebne do wykonania tego notebooka.\n",
    "# W swoim rozwiÄ…zaniu bÄ™dziesz mÃ³gÅ‚ korzystaÄ‡ z innych bibliotek wymienionych\n",
    "# wyÅ¼ej. Miejsce na ich zaimportowanie znajduje siÄ™ poniÅ¼ej w sekcji\n",
    "# na Twoje rozwiÄ…zanie.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import mobilenetv3, MobileNet_V3_Small_Weights\n",
    "import torchinfo\n",
    "import tarfile\n",
    "from tqdm import tqdm, trange\n",
    "from typing import Tuple, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15578bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FINAL_EVALUATION_MODE:\n",
    "    import gdown\n",
    "    import os\n",
    "\n",
    "    GDRIVE_DATA = [\n",
    "        (\"15v0YZx6frCzdVT9zPcoD7Vr-N0mzFKsN\", \"models/mobilenet_v3_small.pth\"),\n",
    "        (\"1gHeU8Of1BYbrFWG3Roi1esYq_pevhSAo\", \"data/val_embeddings.pkl\"),\n",
    "        (\"1p0CHP5APgjx18Iq1Fj5rKq9nRt9ZlP_X\", \"data/Cifar100/train_val.gz\")\n",
    "    ]\n",
    "    \n",
    "    for file_id, output in GDRIVE_DATA:        \n",
    "        url = f'https://drive.google.com/uc?id={file_id}'\n",
    "        os.makedirs(os.path.dirname(output), exist_ok=True)\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        \n",
    "        print(f\"Downloaded: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de20599",
   "metadata": {},
   "source": [
    "## Architektura Modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adedd67f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Jest to klasa reprezentujÄ…ca klasyfikator, ktÃ³ry zostanie uÅ¼yty do\n",
    "    przeksztaÅ‚cenia obrazkÃ³w do ich zanurzeÅ„ (ang. embeddingÃ³w).\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = self.get_net().to(DEVICE)\n",
    "\n",
    "        self.IMAGE_HEIGHT = 224\n",
    "        self.IMAGE_WIDTH = 224\n",
    "        self.INPUT_CHANNELS = 3\n",
    "\n",
    "        if verbose:\n",
    "            self.summary()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_net() -> nn.Module:\n",
    "        mobilenet = mobilenetv3.mobilenet_v3_small(weights=None)\n",
    "        mobilenet.load_state_dict(torch.load('models/mobilenet_v3_small.pth'))\n",
    "        return mobilenet\n",
    "\n",
    "    def summary(self) -> None:\n",
    "        \"\"\"\n",
    "        Wypisuje opis i podsumowanie sieci za pomocÄ… biblioteki \n",
    "        torchinfo. \n",
    "        \"\"\"\n",
    "        print(\n",
    "            torchinfo.summary(\n",
    "                self.net,\n",
    "                input_size=(\n",
    "                    1,\n",
    "                    self.INPUT_CHANNELS,\n",
    "                    self.IMAGE_HEIGHT,\n",
    "                    self.IMAGE_WIDTH,\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def get_embedding(self, x: torch.Tensor) -> torch.Tensor: \n",
    "        \"\"\"\n",
    "        Dla zadanego obrazka `x` zwraca jego embedding\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        return torch.flatten(x, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302570c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inicjacja sieci\n",
    "model = Net(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584b101e",
   "metadata": {},
   "source": [
    "## Åadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b2c5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Klasa reprezentujÄ…ca dataset CIFAR-100. ZbiÃ³r ten jest podzielony na dokÅ‚adnie\n",
    "    100 klas. Klasa udostÄ™pnia metody `get_trian_loader` i `get_val_loader`.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_dataset, val_dataset, verbose: bool = False):\n",
    "        self.dataset_name = \"CIFAR-100\"\n",
    "        self.mean = (0.485, 0.456, 0.406)\n",
    "        self.std = (0.229, 0.224, 0.225)\n",
    "        self.NUM_OF_CLASSES = 100\n",
    "\n",
    "        self.train_dataset = train_dataset\n",
    "\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "        if verbose:\n",
    "            self.summary()\n",
    "\n",
    "    def get_train_loader(self, batch_size: int = 128) -> DataLoader:\n",
    "        \"\"\"Zwraca loader danych treningowych.\"\"\"\n",
    "        return DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def get_val_loader(self, batch_size: int = 128) -> DataLoader:\n",
    "        \"\"\"Zwraca loader danych walidacyjnych.\"\"\"\n",
    "        return DataLoader(self.val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    def summary(self, show_image: bool = True):\n",
    "        \"\"\"WyÅ›wietla krÃ³tkie podsumowanie zbioru danych i przykÅ‚adowy obrazek.\"\"\"\n",
    "        print(f\"\\nðŸ“Š Summary of {self.dataset_name} Dataset\")\n",
    "        print(f\"ðŸ”¢ Number of classes: {self.NUM_OF_CLASSES}\")\n",
    "        print(f\"ðŸ“ Number of training examples: {len(self.train_dataset)}\")\n",
    "        print(f\"ðŸ“ Number of validation examples: {len(self.val_dataset)}\")\n",
    "        print(\n",
    "            f\"ðŸ“¦ Examples per class in train (approx): {len(self.train_dataset) // self.NUM_OF_CLASSES}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"ðŸ“¦ Examples per class in val (approx): {len(self.val_dataset) // self.NUM_OF_CLASSES}\"\n",
    "        )\n",
    "\n",
    "        image, label = self.train_dataset[2]\n",
    "        print(f\"ðŸ–¼ï¸ Example image shape: {image.shape}\")\n",
    "        print(f\"ðŸ·ï¸ Example label: {label} ({self.train_dataset.classes[label]})\")\n",
    "\n",
    "        if show_image:\n",
    "            img_np = image.permute(1, 2, 0)\n",
    "            # unnormalize\n",
    "            img_np = img_np * torch.tensor(self.std) + torch.tensor(self.mean)\n",
    "            img_np = img_np.clip(0, 1).numpy()\n",
    "\n",
    "            plt.imshow(img_np)\n",
    "            plt.title(f\"Class: {label}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0dd72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "READONLY_DATA_PATH = \"data/Cifar100\"\n",
    "OUTPUT_PATH = \"file_output\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "def unpack_tar_gz(filename: str, path: str = OUTPUT_PATH) -> None:\n",
    "    \"\"\" Rozpakowuje archiwum tar.gz \"\"\"\n",
    "    with tarfile.open(filename, \"r:gz\") as tar:\n",
    "        tar.extractall(path=path)\n",
    "        print(f\"Extracted {filename} to {path}\")\n",
    "\n",
    "\n",
    "def load_dataset_from_pkl(filename: str) -> Dataset:\n",
    "    \"\"\" Wczytuje zbiÃ³r danych z pliku .pkl \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd8717a",
   "metadata": {},
   "source": [
    "Ta komÃ³rka uÅ¼ywa wczeÅ›niej zdefiniowanych funkcji, aby zaÅ‚adowaÄ‡ zbiÃ³r treningowy i walidacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362a183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "\n",
    "unpack_tar_gz(\n",
    "    os.path.join(READONLY_DATA_PATH, \"train_val.gz\"), os.path.join(OUTPUT_PATH)\n",
    ")\n",
    "\n",
    "\n",
    "loaded_data = load_dataset_from_pkl(os.path.join(OUTPUT_PATH, \"train_val.pkl\"))\n",
    "\n",
    "# WyodrÄ™bnij zbiÃ³r treningowy i walidacyjny\n",
    "train_dataset = loaded_data[\"train\"]\n",
    "val_dataset = loaded_data[\"val\"]\n",
    "classes = loaded_data[\"classes\"]\n",
    "train_dataset.classes = classes\n",
    "val_dataset.classes = classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66bf1ab",
   "metadata": {},
   "source": [
    "Tu inicjowany jest obiekt typu `Dataset`, aby wczytaÄ‡ obiekty typu Dataloader odpowiednio dla zbioru treningowego i walidacyjnego. Wypisywane jest teÅ¼ podsumowanie zbioru danych (patrz wynik komÃ³rki poniÅ¼ej) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5b583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI #########################\n",
    "\n",
    "ds = Dataset(train_dataset, val_dataset, verbose=True)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_loader = ds.get_train_loader(BATCH_SIZE)\n",
    "val_loader = ds.get_val_loader(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae9a79",
   "metadata": {},
   "source": [
    "## Obliczenie zanurzeÅ„ danych\n",
    "Od teraz bÄ™dziesz pracowaÄ‡ na zanurzeniach danych, ktÃ³re sÄ… reprezentacjami zdjÄ™Ä‡. Dla komfortu pracy, od razu po policzeniu, zanurzenia zapisywane sÄ… na dysku, abyÅ› nie musiaÅ‚ ich obliczaÄ‡ za kaÅ¼dym razem, gdy uruchomisz na nowo notatnik. Wynikiem tej komÃ³rki sÄ… zmienne `train_embeddings`, `val_embeddings`, `train_labels`, `val_labels`. SÄ… to obiekty typu `torch.tensor` zawierajÄ…ce dane testowe i walidacyjne, z ktÃ³rych bÄ™dziesz korzystaÄ‡ w dalszej czÄ™Å›ci notatnika i w swoim rozwiÄ…zaniu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499fd823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "def get_embeddings(model, dataloader: DataLoader) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    WyodrÄ™bnia embeddingi i etykiety z modelu dla danych z dataloadera.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, batch_labels in tqdm(dataloader):\n",
    "            images, batch_labels = images.to(DEVICE), batch_labels.to(DEVICE)\n",
    "            batch_embeddings = model.get_embedding(images)\n",
    "            embeddings.append(batch_embeddings)\n",
    "            labels.append(batch_labels)\n",
    "    return torch.cat(embeddings), torch.cat(labels)\n",
    "\n",
    "\n",
    "def save_embeddings(embeddings: torch.Tensor, labels: torch.Tensor, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Zapisuje embeddingi i etykiety do pliku.\n",
    "    \"\"\"\n",
    "    data = {\"embeddings\": embeddings, \"labels\": labels}\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "def load_embeddings(filename: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Åaduje embeddingi i etykiety z pliku.\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data[\"embeddings\"], data[\"labels\"]\n",
    "\n",
    "\n",
    "embedding_path = os.path.join(OUTPUT_PATH, \"train_embeddings.pkl\")\n",
    "val_embedding_path = os.path.join(OUTPUT_PATH, \"val_embeddings.pkl\")\n",
    "\n",
    "# Oblicz embeddingi lub wczytaj wczeÅ›niej policzone z pliku\n",
    "if os.path.exists(embedding_path):\n",
    "    print(f\"Loading cached training embeddings from: {embedding_path}\")\n",
    "    train_embeddings, train_labels = load_embeddings(embedding_path)\n",
    "else:\n",
    "    print(\"Generating new training embeddings...\")\n",
    "    train_embeddings, train_labels = get_embeddings(model, train_loader)\n",
    "    save_embeddings(train_embeddings, train_labels, embedding_path)\n",
    "    print(f\"Saved training embeddings to: {embedding_path}\")\n",
    "\n",
    "if os.path.exists(val_embedding_path):\n",
    "    print(f\"Loading cached validation embeddings from: {val_embedding_path}\")\n",
    "    val_embeddings, val_labels = load_embeddings(val_embedding_path)\n",
    "else:\n",
    "    print(\"Generating new validation embeddings...\")\n",
    "    val_embeddings, val_labels = get_embeddings(model, val_loader)\n",
    "    save_embeddings(val_embeddings, val_labels, val_embedding_path)\n",
    "    print(f\"Saved validation embeddings to: {val_embedding_path}\")\n",
    "\n",
    "train_embeddings = train_embeddings.to(DEVICE)\n",
    "val_embeddings = val_embeddings.to(DEVICE)\n",
    "\n",
    "train_labels = train_labels.to(DEVICE)\n",
    "val_labels = val_labels.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02465ae5",
   "metadata": {},
   "source": [
    "## Kod z kryterium oceniajÄ…cym\n",
    "PoniÅ¼szy kod bÄ™dzie uÅ¼ywany do oceny rozwiÄ…zania na zbiorze testowym. JedynÄ… zmianÄ… bÄ™dzie podmiana zbioru walidacyjnego na tajny zbiÃ³r testowy. MoÅ¼esz tej klasy uÅ¼yÄ‡ do sprawdzania swojego rozwiÄ…zania na zbiorze walidacyjnym doÅ‚Ä…czonym do zadania. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d40258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "def accuracy(\n",
    "    prototypes: torch.Tensor,\n",
    "    prototypes_labels: torch.Tensor,\n",
    "    embeddings_val: torch.Tensor,\n",
    "    labels_val: torch.Tensor\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Oblicza dokÅ‚adnoÅ›Ä‡ klasyfikacji na podstawie najbliÅ¼szych prototypÃ³w.\n",
    "    \"\"\"\n",
    "    dist = torch.cdist(embeddings_val, prototypes)\n",
    "    idx = dist.argmin(dim=1).to(prototypes.device)\n",
    "    predictions = prototypes_labels[idx]\n",
    "    predicted_class = predictions.clone().detach().to(labels_val.device)\n",
    "    return (predicted_class == labels_val).to(torch.float32).mean().item()\n",
    "\n",
    "\n",
    "class SolutionHolder():    \n",
    "    \"\"\"\n",
    "    Klasa odpowiedzialna za rejestrowanie i ocenÄ™ rozwiÄ…zaÅ„ prototypowych\n",
    "    w oparciu o dane embeddingÃ³w i etykiet.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_embeddings: torch.Tensor,\n",
    "        train_labels: torch.Tensor,\n",
    "        val_embeddings: torch.Tensor,\n",
    "        val_labels: torch.Tensor\n",
    "    ):\n",
    "        self.train_embeddings = train_embeddings\n",
    "        self.train_labels = train_labels\n",
    "        self.val_embeddings = val_embeddings\n",
    "        self.val_labels = val_labels\n",
    "        self.sol_list = []\n",
    "    \n",
    "    def assert_solution(self, prototypes: torch.Tensor, prototypes_labels: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Sprawdza, czy rozwiÄ…zanie speÅ‚nia wymagane warunki.\n",
    "        \"\"\"\n",
    "        # StaÅ‚e wymagane warunki\n",
    "        REQUIRED_NUM_PROTOTYPES = 150\n",
    "        MAX_LABEL = 100\n",
    "        DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Sprawdzenie typÃ³w\n",
    "        assert isinstance(prototypes, torch.Tensor), \"prototypes musi byÄ‡ typu torch.Tensor\"\n",
    "        assert isinstance(prototypes_labels, torch.Tensor), \"prototypes_labels musi byÄ‡ typu torch.Tensor\"\n",
    "\n",
    "        # Sprawdzenie typu danych\n",
    "        assert prototypes.dtype == torch.float32, \"prototypes.dtype musi byÄ‡ torch.float32\"\n",
    "        assert prototypes_labels.dtype == torch.long, \"prototypes_labels.dtype musi byÄ‡ torch.long\"\n",
    "\n",
    "        # Sprawdzenie ksztaÅ‚tÃ³w\n",
    "        assert prototypes.shape[0] == REQUIRED_NUM_PROTOTYPES, f\"prototypes powinien mieÄ‡ 150 wierszy, otrzymano {prototypes.shape[0]}\"\n",
    "        assert prototypes_labels.shape[0] == REQUIRED_NUM_PROTOTYPES, f\"prototypes_labels powinien mieÄ‡ 150 elementÃ³w, otrzymano {prototypes_labels.shape[0]}\"\n",
    "        assert len(prototypes_labels.shape) == 1, \"prototypes_labels musi byÄ‡ wektorem 1D\"\n",
    "\n",
    "        # Sprawdzenie wartoÅ›ci etykiet\n",
    "        assert torch.all((prototypes_labels >= 0) & (prototypes_labels < MAX_LABEL)), \"Wszystkie etykiety w prototypes_labels muszÄ… byÄ‡ w zakresie [0, 100)\"\n",
    "\n",
    "    \n",
    "    def register_class_solution(self, solution_class: Type, name: str) -> None:\n",
    "        \"\"\"\n",
    "        Rejestruje rozwiÄ…zanie na podstawie klasy zawierajÄ…cej metodÄ™ get_prototypes.\n",
    "        \"\"\"\n",
    "        solution = solution_class()\n",
    "        prototypes, prototypes_labels = solution.get_prototypes(self.train_embeddings, self.train_labels)\n",
    "        self.assert_solution(prototypes, prototypes_labels)\n",
    "        self.register_solution(prototypes, prototypes_labels, name)\n",
    "\n",
    "    def register_solution(self, prototypes: torch.Tensor, prototypes_labels: torch.Tensor, name: str) -> None:\n",
    "        \"\"\"\n",
    "        Dodaje rozwiÄ…zanie do listy rozwiÄ…zaÅ„.\n",
    "        \"\"\"\n",
    "        self.sol_list.append({\n",
    "            \"name\": name,\n",
    "            \"prototypes\": prototypes.to(DEVICE),\n",
    "            \"prototypes_labels\": prototypes_labels.to(DEVICE),\n",
    "        })\n",
    "\n",
    "    def points_from_accuracy(self, acc: float) -> int:\n",
    "        \"\"\"\n",
    "        Przelicza dokÅ‚adnoÅ›Ä‡ na liczbÄ™ punktÃ³w (0â€“100).\n",
    "        \"\"\"\n",
    "        result = (acc - 0.4) / (0.68 - 0.4) * 100\n",
    "        result = int(round(result))\n",
    "        return min(100, max(0, result))\n",
    "\n",
    "    def _print_one_solution(\n",
    "        self,\n",
    "        prototypes: torch.Tensor,\n",
    "        prototypes_labels: torch.Tensor,\n",
    "        name: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        WyÅ›wietla dokÅ‚adnoÅ›Ä‡ i liczbÄ™ punktÃ³w dla jednego rozwiÄ…zania.\n",
    "        \"\"\"\n",
    "        acc_val = accuracy(prototypes, prototypes_labels, self.val_embeddings, self.val_labels)\n",
    "        points = self.points_from_accuracy(acc_val)\n",
    "        print(f\"{name} ({prototypes.shape[0]} prototypes) Validation Accuracy: {acc_val * 100:.2f}% | (Points {points})\")\n",
    "\n",
    "    def print_solutions(self) -> None:\n",
    "        \"\"\"\n",
    "        WyÅ›wietla wyniki dla wszystkich zarejestrowanych rozwiÄ…zaÅ„.\n",
    "        \"\"\"\n",
    "        for sol_dict in self.sol_list:\n",
    "            name = sol_dict['name']\n",
    "            prototypes = sol_dict['prototypes']\n",
    "            prototypes_labels = sol_dict['prototypes_labels']\n",
    "            \n",
    "            self._print_one_solution(\n",
    "                prototypes,\n",
    "                prototypes_labels,\n",
    "                name\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9f2919",
   "metadata": {},
   "source": [
    "# Twoje RozwiÄ…zanie\n",
    "W tej sekcji naleÅ¼y umieÅ›ciÄ‡ Twoje rozwiÄ…zanie. Wprowadzaj zmiany wyÅ‚Ä…cznie tutaj!\n",
    "\n",
    "Aktualne rozwiÄ…zanie polega na losowaniu prototypÃ³w ze zbioru treningowego.\n",
    "Twoim zadaniem jest zmodyfikowanie klasy `YourSolution`. \n",
    "\n",
    "Twoja klasa `YourSolution` powinna posiadaÄ‡ metodÄ™:\n",
    "\n",
    "```python\n",
    "def get_prototypes(self, train_embeddings, train_labels) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    ...\n",
    "    return prototypes, prototypes_labels\n",
    "```\n",
    "\n",
    "Metoda ta powinna zwracaÄ‡ krotkÄ™ dwÃ³ch obiektÃ³w typu torch.Tensor.\n",
    "\n",
    "- Pierwszy tensor, nazwany `prototypes`, powinien mieÄ‡ ksztaÅ‚t `[150, D]`, gdzie `D` to wymiar zanurzeÅ„ (ang. embeddings).\n",
    "\n",
    "    `prototypes.device` powinien byÄ‡ rÃ³wny staÅ‚ej `DEVICE`, zdefiniowanej poniÅ¼ej.\n",
    "\n",
    "    `prototypes.dtype` powinien byÄ‡ `torch.float32`.\n",
    "\n",
    "- Drugi tensor, `prototypes_labels`:\n",
    "\n",
    "    Powinien mieÄ‡ ksztaÅ‚t `[150]`.\n",
    "\n",
    "    Typ danych: `torch.long`.\n",
    "\n",
    "    KaÅ¼da wartoÅ›Ä‡ powinna naleÅ¼eÄ‡ do zakresu `0 <= class < 100`.\n",
    "\n",
    "Te wymagania bÄ™dÄ… sprawdzane przez klasÄ™ SolutionHolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11eff873-65b8-482e-919e-b350ec3b710e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Twoje importy ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08949483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YourSolution(): \n",
    "    def get_random_150_samples(self, unique_labels: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Przydziela losowo 1â€“2 prÃ³bki na klasÄ™, Å‚Ä…cznie 150 prÃ³bek.\n",
    "        \"\"\"\n",
    "        num_samples_per_class = np.ones_like(unique_labels)\n",
    "        double_samples = np.random.choice(\n",
    "            num_samples_per_class.shape[0],\n",
    "            50,\n",
    "            replace = False\n",
    "        )\n",
    "        num_samples_per_class[double_samples] = num_samples_per_class[double_samples] + 1\n",
    "\n",
    "        return num_samples_per_class\n",
    "\n",
    "    def get_random_samples_per_class(\n",
    "        self,\n",
    "        embeddings: torch.Tensor,\n",
    "        labels: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Wybiera losowo prÃ³bki embeddingÃ³w z kaÅ¼dej klasy na podstawie rozkÅ‚adu.\n",
    "        \"\"\"\n",
    "        embeddings = embeddings.numpy(force=True)\n",
    "        labels = labels.numpy(force=True)\n",
    "\n",
    "        unique_labels = np.unique(labels)\n",
    "        num_samples_per_class = self.get_random_150_samples(unique_labels)\n",
    "\n",
    "        random_samples = []\n",
    "        for i, label in enumerate(unique_labels):\n",
    "            class_indices = np.where(labels == label)[0]\n",
    "            selected_indices = np.random.choice(class_indices, size=num_samples_per_class[i], replace=False)\n",
    "            random_samples.extend(selected_indices)\n",
    "\n",
    "        return torch.tensor(embeddings[random_samples], device=DEVICE), \\\n",
    "                torch.tensor(labels[random_samples], device=DEVICE)\n",
    "        \n",
    "    def get_prototypes(\n",
    "        self,\n",
    "        train_embeddings: torch.Tensor,\n",
    "        train_labels: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Zwraca 150 losowych prototypÃ³w i odpowiadajÄ…ce im etykiety.\n",
    "\n",
    "        [WAÅ»NE] PamiÄ™taj, aby zaimplementowaÄ‡ w swojej klasie metodÄ™ `get_prototypes`\n",
    "        tak jak opisano w sekcji `Ograniczenia`. Ta metoda moÅ¼e Ci sÅ‚uÅ¼yÄ‡ jako wzÃ³r. \n",
    "        \"\"\"\n",
    "        prototypes, prototypes_labels = self.get_random_samples_per_class(\n",
    "            train_embeddings, train_labels\n",
    "        )\n",
    "        prototypes = prototypes.to(DEVICE)\n",
    "        prototypes_labels = prototypes_labels.to(DEVICE)\n",
    "        return prototypes, prototypes_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d12d5f",
   "metadata": {},
   "source": [
    "# Ewaluacja\n",
    "Uruchomienie poniÅ¼szych komÃ³rek pozwoli sprawdziÄ‡, ile punktÃ³w zdobyÅ‚oby Twoje rozwiÄ…zanie na danych walidacyjnych. Przed wysÅ‚aniem upewnij siÄ™, Å¼e caÅ‚y notebook (rÃ³wnieÅ¼ z ustawionÄ… flagÄ… FINAL_EVALUATION_MODE = True) wykonuje siÄ™ od poczÄ…tku do koÅ„ca bez bÅ‚Ä™dÃ³w i bez koniecznoÅ›ci ingerencji uÅ¼ytkownika po wybraniu opcji \"Run All\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2b6e613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your solution (150 prototypes) Validation Accuracy: 18.34% | (Points 0)\n"
     ]
    }
   ],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "if not FINAL_EVALUATION_MODE:   \n",
    "    solution_holder = SolutionHolder(\n",
    "        train_embeddings=train_embeddings,\n",
    "        train_labels=train_labels,\n",
    "        val_embeddings=val_embeddings,\n",
    "        val_labels=val_labels,\n",
    "    )\n",
    "\n",
    "    solution_holder.register_class_solution(YourSolution, \"Your solution\")\n",
    "    solution_holder.print_solutions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9473627",
   "metadata": {},
   "source": [
    "MoÅ¼esz rejestrowaÄ‡ rÃ³Å¼ne swoje rozwiÄ…zania do oceny za pomocÄ… poniÅ¼szej komÃ³rki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea49fd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your solution (150 prototypes) Validation Accuracy: 18.34% | (Points 0)\n",
      "Different solution (150 prototypes) Validation Accuracy: 17.97% | (Points 0)\n"
     ]
    }
   ],
   "source": [
    "if not FINAL_EVALUATION_MODE:   \n",
    "    solution_holder.register_class_solution(YourSolution, \"Different solution\")\n",
    "    solution_holder.print_solutions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e90b8",
   "metadata": {},
   "source": [
    "PonieÅ¼ej znajduje siÄ™ komorka, ktÃ³ra automatycznie zapisze twoje prototypy na sprawdzarce, aby mogÅ‚a uÅ¼yÄ‡ ich do klasyfikacji zbioru testowego. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "429b8513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÃ“RKI ##########################\n",
    "if FINAL_EVALUATION_MODE: \n",
    "    solution = YourSolution()\n",
    "    prototypes, prototypes_labels = solution.get_prototypes(\n",
    "        train_embeddings, \n",
    "        train_labels\n",
    "    )\n",
    "     \n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    torch.save(prototypes, os.path.join(OUTPUT_PATH, \"prototypes.pt\"),)\n",
    "    torch.save(prototypes_labels, os.path.join(OUTPUT_PATH, \"prototypes_labels.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce96cbd-10d2-4e74-a42e-071894d23186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

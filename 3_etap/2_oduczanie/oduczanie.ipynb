{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Od)uczenie maszynowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://live.staticflickr.com/65535/54548177187_3b31449095_b.jpg\" style=\"height: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Obraz wygenerowany przy użyciu modelu DALL-E.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motywacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oduczanie maszynowe (ang. *machine unlearning*) jest fascynującym i coraz bardziej popularnym tematem związanym z algorytmami uczącymi się, przede wszystkim z sieciami głębokiego uczenia. Wraz z rosnącą liczbą parametrów oraz zaawansowaniem modeli, ich zdolność do usuwania przedawnionych, błędnych lub wrażliwych informacji (np. związanych z prywatnością użytkownika) staje się kluczowa. Oduczanie umożliwia *usunięcie z pamięci modelu* wybranych informacji w sposób, który minimalizuje związaną z tym szkodę w odniesieniu do innych wyuczonych danych. Dzięki temu możemy osiągnąć bardziej precyzyjne i bezpieczne modele, bez ciągłej potrzeby trenowania modeli od początku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korzyści"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wprowadzenie oduczania w świat sieci głębokiego uczenia może przynieść wiele korzyści. Pozwala między innymi na pozbycie się zdolności modelu do generowania niebezpiecznych treści. Przykładowo, jeśli generatywny model został przeszkolony na ogromnym zbiorze obrazów, ale część z nich zawiera nieodpowiednie treści, takie jak nagość, można zastosować oduczanie, aby pozbyć się konceptu nagości z pamięci modelu, co zmniejszy prawdopodobieństwo wygenerowania w przyszłości podobnych obrazów.\n",
    "\n",
    "Po drugie, w związku z przepisami o ochronie danych osobowych (jak choćby GDPR, czyli *General Data Protection Regulation* w Unii Europejskiej), użytkownicy mają prawo wycofać zgodę na przetwarzanie ich danych przez daną firmę. Jeśli jednak model został wyuczony z użyciem tych danych, nie jest trywialne pozbycie się tej wiedzy bez konieczności ponownego treningu modelu.\n",
    "\n",
    "Wreszcie, oduczanie może pomóc w eliminacji uprzedzeń i błędów, które mogą pojawić się w modelach, co prowadzi do bardziej sprawiedliwych i dokładnych wyników. Modele uczenia maszynowego mogą czasami przyswajać uprzedzenia i nierówności zawarte w danych treningowych (choćby związane z płcią czy kolorem skóry), co skutkuje stronniczymi predykcjami. Oduczanie pozwala na usunięcie tych uprzedzeń, co poprawia jakość i sprawiedliwość wyników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<u>Uwaga</u>: W klasycznym problemie oduczania maszynowego, nie tyle chcemy, żeby model nie potrafił przewidywać danej klasy, ale raczej, żeby zachowywał się tak, jakby tych danych nie było w zbiorze treningowym (co oznacza odporność modelu na atak wnioskowania o członkostwie, ang. *membership inference attack*). Stąd często pożądaną własnością nie jest bezpośrednie minimalizowanie skuteczności na pewnej części danych, tylko dążenie do tego, aby model zachowywał się wobec nich losowo lub tak jak wobec danych, których faktycznie nie było w zbiorze treningowym. Na potrzeby naszego zadania upraszczamy ten cel i chcemy, by model po prostu przewidywał daną klasę z jak najmniejszą dokładnością.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opis problemu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na potrzeby naszej przygody z oduczaniem będziemy analizować problem klasyfikacji na standardowym zbiorze wizji komputerowej, Fashion MNIST. Do rozwiązania tego problemu użyjemy klasycznej architektury konwolucyjnej LeNet (wizualizacja i opis poniżej). Mamy dostarczony bazowy model, który został wytrenowany na całym zbiorze danych, czyli na wszystkich dziesięciu klasach zbioru Fashion MNIST (t-shirt, spodnie, sweter, sukienka, płaszcz, sandał, koszula, but sportowy, torba, trampek). Poniżej znajduje się kod do wczytania tego modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twoje zadanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twoim zadaniem jest oduczenie bazowego modelu danej wybranej klasy zbioru Fashion MNIST. Wymagamy, żeby ostatnia warstwa (warstwa klasyfikacyjna) pozostała __nienaruszona__, innymi słowy aby Twoja ingerencja była na poziomie ekstraktora cech, a nie poprzez mechaniczną modyfikację sygnału odpowiedzialnego za generowanie logitów do poszczególnych klas. Ingerencja powinna koncentrować się wyłącznie na poziomie wcześniejszych warstw modelu, z wyłączeniem jakiejkolwiek bezpośredniej zmiany w samej funkcji klasyfikującej modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby sprawdzić, jak sobie poradziłeś z tym zadaniem, przygotowaliśmy zestaw metryk, które pozwolą ocenić jakość Waszego rozwiązania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Będziemy Cię oceniać pod kątem czterech aspektów:\n",
    "- **Oduczenie klasyfikacji wybranej klasy** - w końcu o to chodzi w oduczaniu! Nie wiesz jednak, na oduczaniu której klasy będziesz oceniany finalnie, w ramach zbioru testowego. W ramach walidacji przyjęliśmy w tym notebooku jedną z dziesięciu klas zbioru Fashion MNIST, ale pamiętaj, że ostatecznie będziesz oceniany na innej klasie!\n",
    "- **Zachowanie wysokiej wydajności na pozostałych klasach** - model musi przestać działać tylko na wybranej klasie, ale nie może stracić wydajności na pozostałych klasach - tutaj dokładność musi być jak najwyższa!\n",
    "- **Ingerencja w bazowy model** - postaraj się, aby modyfikacja wag bazowego modelu była możliwie najmniejsza!\n",
    "- **Różnorodność predykcji dla zapomnianej klasy** - chodzi o to, aby model był odporny na wspomniany wcześniej atak wnioskowania o członkostwie, czyli aby nie dało się poznać, że model kiedykolwiek widział dane, których ma się oduczyć!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szczegółowy opis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oduczenie i-tej klasy, $i \\in \\lbrace 1, ..., 10 \\rbrace$.\n",
    "\n",
    "Proces oduczenia znajomości i-tej klasy (jednej spośród dziesięciu możliwych klas) polega na __usunięciu zdolności modelu do rozpoznawania i klasyfikowania danych należących do tej konkretnej klasy__. Jest to kluczowy aspekt oduczania, który pozwala na eliminację niepożądanych lub nieodpowiednich danych z modelu.\n",
    "Konkretnie, możemy mierzyć __dokładność__ (ang. accuracy) na danych __należących do konkretnej__ klasy o numerze i jako $\\Psi_{i}$:\n",
    "\n",
    "$$ \\Psi_{i} = \\frac{TP_i}{TP_i + FN_i}, $$\n",
    "\n",
    "gdzie $TP_i$ oznacza liczbę przykładów poprawnie zaklasyfikowanych do klasy $i$ (odsetek prawdziwie pozytywnych), a $FN_i$ oznacza liczbę przykładów z klasy $i$, które zostały błędnie zaklasyfikowane jako należące do innej klasy (odsetek falszywie negatywnych).\n",
    "W naszym problemie chcemy __minimalizować__ wartość $\\Psi_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zachowanie wysokiej wydajności na pozostałych klasach \n",
    "\n",
    "Ważnym aspektem oduczania jest zapewnienie, że __usunięcie i-tej klasy nie wpłynie negatywnie na wydajność modelu w odniesieniu do pozostałych klas__. Model musi nadal być w stanie osiągać wysoką dokładność klasyfikacji na wszystkich pozostałych klasach. Jest to wyzwanie, ponieważ proces oduczania może  zakłócić równowagę modelu i wpłynąć negatywnie na jego zdolność do ekstrakcji cech, także w odniesieniu do pozostałych klas. Zbiór tych danych, które powinny wciąż być dobrze klasyfikowane przez model, nazywamy po prostu zbiorem pozostałych danych (ang. *remain dataset*). Możemy ocenić dokładność klasyfikacji modelu na tych danych, mierząc ją dla wszystkich klas z wyłączeniem klasy o numerze $i$ i ustalić to jako funkcję $\\Phi$ zależną od $i$.\n",
    "\n",
    "Konkretnie, możemy użyć dokładność na zbiorze pozostałym jako $\\Phi_{i}$:\n",
    "$$\n",
    "\\Phi_{i} = \\frac{\\sum_{k \\neq i} TP_k}{\\sum_{k \\neq i} \\left( TP_k + FN_k \\right)},\n",
    "$$\n",
    "gdzie: $TP_k$ to liczba prawidłowo zaklasyfikowanych przykładów należących do klasy $k$, z wyłączeniem klasy $i$ (odsetek prawdziwie pozytywnych), $FN_k$ to liczba przykładów błędnie niezaklasyfikowanych jako klasa $k$, z wyłączeniem klasy $i$ (odsetek fałszywie negatywnych). Innymi słowy, licznik zawiera liczbę poprawnie zaklasyfikowanych przykładów z wszystkich klas, oprócz klasy o numerze $i$, a mianownik ilość przykładów należących do wszystkich klas, z wyłączeniem $i$-tej klasy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingerencja w bazowy model\n",
    "\n",
    "Proces oduczania wiąże się z ingerencją w bazowy model, co może mieć różne konsekwencje. Ważne jest, aby ta __ingerencja była minimalna__ i nie prowadziła do destabilizacji modelu. W praktyce oznacza to, że zmiany wprowadzone w modelu powinny być ograniczone do niezbędnych modyfikacji, które pozwolą na usunięcie klasy i-tej, bez wpływu na strukturę i funkcjonalność modelu, zatem z minimalną modyfikacją parametrów modelu. Wymagamy, aby __ostatnia warstwa w modelu LeNet została nienaruszona__, ale będziemy też mierzyć odległość między wyjściowym a oduczonym modelem, zaproponowanym przez Ciebie. Jest to również sposób na lepsze zrozumienie działania modelu. Jeśli odległość od bazowego modelu nie jest zbyt duża, a mamy zaufanie do bazowego modelu, to uzyskany przez Ciebie model jest wystarczająco bliski, aby wzbudzać nasze zaufanie. \n",
    "\n",
    "W naszym problemie będziemy posługiwać się tradycyjną **odległością** $\\mathbf{L_2}$, którą można wyrazić wzorem:\n",
    "\n",
    "$$ \\mathcal{d}_{dist} = \\mathcal{L_2} (\\theta; \\theta_0) = \\sqrt{\\sum_j (\\theta_j - \\theta_{0,j})^2}, $$\n",
    "\n",
    "gdzie\n",
    "- $\\theta$ oznacza wektor parametrów modelu po procesie oduczania,\n",
    "- $\\theta_0$ oznacza wektor parametrów bazowego modelu,\n",
    "- $\\theta_j$ oraz $\\theta_{0,j}$ to odpowiednie wartości parametrów dla j-tego warstwy modeli.\n",
    "\n",
    "Odległość $\\mathcal{L}_2$ sumuje kwadraty różnic odległości między kolejnymi warstwami modelu bazowego w odniesieniu do odpowiadających warstw zmodyfikowanego modelu, a finalnie liczy pierwiastek z tej sumy. Im mniejsza wartość $\\mathcal{d}_{dist}$, tym mniejsza ingerencja w bazowy model, co jest pożądane w kontekście minimalizacji zmian w strukturze modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Różnorodność predykcji dla zapomnianej klasy\n",
    "\n",
    "Ostatnim aspektem oceny jest __różnorodność predykcji dla zapomnianej klasy__. Po procesie oduczania model powinien generować różnorodne predykcje dla danych, które należą do klasy $i$, którą miał zapomnieć model. Oznacza to, że model powinien po prostu przypisywać je do innych klas w sposób zróżnicowany tak, aby nie dało się łatwo stwierdzić, czy dane te znajdowały się pierwotnie w zbiorze treningowym bazowego modelu.\n",
    "\n",
    "Model nie powinien również przypisywać wszystkich predykcji do jednej konkretnej klasy, ponieważ mogłoby to być interpretowane jako scalenie wybranych klas, co nie jest przez nas pożądane.\n",
    "\n",
    "Aby zmierzyć różnorodność predykcji, wykorzystamy __dywergencję Kullbacka-Leiblera (KL)__. Jest to standardowa miara rozbieżności między dwoma rozkładami prawdopodobieństwa. W naszym przypadku badamy odległość rozkładu predykcji modelu od rozkładu jednostajnego, co oznacza, że żadna z pozostałych klas nie powinna być faworyzowana.\n",
    "\n",
    "Dywergencję KL definiujemy jako:\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_{KL}(p \\parallel u) = \\sum_{c=1}^{C} p(c) \\log \\left( \\frac{p(c)}{u(c)} \\right),\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "- $p(c)$ to prawdopodobieństwo przypisane przez model próbki do klasy $c$,\n",
    "- $u(c)$ to prawdopodobieństwo zgodne z rozkładem jednostajnym, czyli $u(c) = \\frac{1}{C}$,\n",
    "- $C$ to liczba wszystkich klas.\n",
    "\n",
    "W przypadku idealnej różnorodności predykcji dla zapomnianej klasy, rozkład $p(c)$ powinien być jak najbardziej zbliżony do rozkładu jednostajnego $u(c)$, co oznacza minimalną wartość $\\mathcal{D}_{KL}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli KL dywergencja jest wciąż dość skomplikowana, nie martw się - w zakładce **Informacje Uzupełniające** dostarczyliśmy kilka pomocnych wskazówek. Dodatkowo zerknij na kod definicji funkcji - pozostawiliśmy w nim kilka komentarzy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie z powyższych czterech celów będziemy ewaluować na danych Fashion MNIST, **jednak nie wiesz, której z klas będziemy chcieli się finalnie oduczyć**. **Ponadto nie wiesz, jaki podzbiór danych z poszczególnych klas będzie wykorzystany do oduczania.** Do przygotowania rozwiązania możesz wybrać sobie dowolną klasę, ale rozwiązanie to musi być gotowe do oduczenia każdej z klas tego zbioru. O ile rozkład danych w zbiorze testowym będzie podobny do rozkładu w tym notebooku, postaraj się uniknąć nadmiernego dopasowania do wybranych danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdź więc, czy Twoje rozwiązanie jest uniwersalne. Upewnij się, że działa na różnych etykietach zleconych do zapomnienia oraz różnych zbiorach danych (architektura jest niezmienna, dopasowana do przetwarzania danych wizyjnych o wymiarze $28 \\times 28$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalna ocena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Całościowo, Twój wynik można matematycznie zapisać jako suma ważona:\n",
    "$$\n",
    "\\Sigma_{score} = \\frac{1}{4} \\cdot \\Sigma_{target} + \\frac{1}{4} \\cdot \\Sigma_{remain} + \\frac{1}{4} \\cdot \\Sigma_{dist} + \\frac{1}{4} \\cdot \\Sigma_{kl}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<u>Uwaga</u>: Metrykę $\\Phi$ chcielibyśmy maksymalizować, a pozostałe, czyli $\\Psi$, $d_{dist}$ oraz $\\mathcal{D}_{KL}$, minimalizować. Stąd należy zwrócić uwagę kolejność odejmowania przy liczeniu poszczególnych składników $\\Sigma$ do końcowej ewaluacji!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Sigma_{target}$ – punktacja za skuteczność oduczania na wybranej klasie (dla uproszczenia, w zadaniu przyjmujemy, że im niższa skuteczność na klasie docelowej, tym lepiej; skalowana w zakresie [0, 100] według progów $[0.09, 0.3]$):\n",
    "\n",
    "$$\n",
    "\\Sigma_{target}(\\Psi_{i}) = \n",
    "\\begin{cases}\n",
    "100 & \\text{jeśli } \\Psi_{i} \\leq 0.09 \\\\\n",
    "0 & \\text{jeśli } \\Psi_{i} \\geq 0.3 \\\\\n",
    "100 \\cdot \\dfrac{0.3 - \\Psi_{i}}{0.3 - 0.09} & \\text{w przeciwnym razie}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$\\Sigma_{other}$ – punktacja za zachowanie dokładności na pozostałych klasach (im wyższa skuteczność, tym wyższy wynik tej metryki; skalowana w zakresie [0, 100] według progów $[0.87, 0.90]$):\n",
    "\n",
    "$$\n",
    "\\Sigma_{other}(\\Phi_{i}) = \n",
    "\\begin{cases}\n",
    "100 & \\text{jeśli } \\Phi_{i} \\geq 0.90 \\\\\n",
    "0 & \\text{jeśli } \\Phi_{i} \\leq 0.87 \\\\\n",
    "100 \\cdot \\dfrac{\\Phi_{i} - 0.87}{0.90 - 0.87} & \\text{w przeciwnym razie}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$\\Sigma_{dist}$ – punktacja za stopień ingerencji w model (im mniejsza odległość $L_2$, tym wyższy wynik tej metryki; skalowana w zakresie [0, 100] według progów $[1.3, 3.0]$):\n",
    "\n",
    "$$\n",
    "\\Sigma_{dist}(\\mathcal{d}_{dist}) = \n",
    "\\begin{cases}\n",
    "100 & \\text{jeśli } \\mathcal{d}_{dist} \\leq 1.3 \\\\\n",
    "0 & \\text{jeśli } \\mathcal{d}_{dist} \\geq 3.0 \\\\\n",
    "100 \\cdot \\dfrac{3.0 - \\mathcal{d}_{dist}}{3.0 - 1.3} & \\text{w przeciwnym razie}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$\\Sigma_{kl}$ – punktacja za różnorodność predykcji (im niższa dywergencja KL, tym wyższy wynik tej metryki; skalowana w zakresie [0, 100] według progów $[0.2, 0.5]$):\n",
    "\n",
    "$$\n",
    "\\Sigma_{kl}(\\mathcal{D}_{KL}) = \n",
    "\\begin{cases}\n",
    "100 & \\text{jeśli } \\mathcal{D}_{KL} \\leq 0.2 \\\\\n",
    "0 & \\text{jeśli } \\mathcal{D}_{KL} \\geq 0.5 \\\\\n",
    "100 \\cdot \\dfrac{0.5 - \\mathcal{D}_{KL}}{0.5 - 0.2} & \\text{w przeciwnym razie}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jednakże**, zadanie jest oceniane **z góry na 0 punktów we wszystkich kategoriach**, jeżeli Twoje rozwiązanie:\n",
    "- nie zastosuje się do wytycznych, czyli przykładowo:\n",
    "    - będzie wprowadzona zmiana w architekturze sieci; \n",
    "    - zostanie zmodyfikowana ostatnia warstwa sieci;\n",
    "    - dokonana będzie jakakolwiek próba oszustwa, polegająca np. na modyfikacji funkcji ewaluacyjnej;\n",
    "- rozwiązanie będzie niesatysfakcjonujące:\n",
    "    - dokładność klasyfikacji na zbiorze klasy do zapomnienia utrzyma się powyżej 0.5;\n",
    "    - dokładność klasyfikacji na zbiorze pozostałych klas spadnie poniżej 0.75;\n",
    "    - dystans $L_2$ będzie większy niż 8.0;\n",
    "    - wartość dywergencji Kullbacka-Leiblera przekroczy 1.75.\n",
    "\n",
    "Ponadto, zaproponowane przez Ciebie oduczanie modelu, tj. działanie funkcji *unlearn()*, może trwać nie dłużej niż 5 minut z użyciem GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za zadanie możesz otrzymać maksymalnie 100 punktów.\n",
    "\n",
    "Pamiętaj, że podczas sprawdzania flaga *FINAL_EVALUATION_MODE* zostanie ustawiona na True.\n",
    "\n",
    "Powodzenia!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kod startowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "# W razie potrzeby, importuj dodatkowe biblioteki poniżej, u siebie w kodzie.\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import tarfile\n",
    "import tempfile\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Używam urządzenia: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # Podczas sprawdzania ustawimy tę flagę na True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "seed = 101\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "class FilteredFashionMNIST(datasets.FashionMNIST):\n",
    "    def __init__(self, *args, classes=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.classes = classes\n",
    "        if self.classes is not None:\n",
    "            self.data, self.targets = self._filter_classes(\n",
    "                self.data, self.targets, self.classes)\n",
    "\n",
    "    def _filter_classes(self, data, targets, classes):\n",
    "        mask = torch.zeros_like(targets, dtype=torch.bool)\n",
    "        for c in classes:\n",
    "            mask = mask | (targets == c)\n",
    "        return data[mask], targets[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "tempdir = tempfile.TemporaryDirectory()\n",
    "TMP_DIR = tempdir.name\n",
    "DATA_PATH = os.path.join(TMP_DIR, \"data\")\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    import gdown\n",
    "\n",
    "    GDRIVE_DATA = [\n",
    "        (\"1SeXrzvs64MBG57ayK6965cya3WRfCMx_\", \"data/FashionMNIST.tar.gz\"),\n",
    "        (\"1mqzxg-_0PJjvErvfwOGad6siNcQKqwk5\", \"data/FilteredFashionMNIST.tar.gz\"),\n",
    "        (\"1YSn8EFjbYDcDCVdlByA_kDKCg4VZLwH8\", \"models/lenet_base_final.pt\"),\n",
    "    ]\n",
    "    \n",
    "    for file_id, output in GDRIVE_DATA:        \n",
    "        url = f'https://drive.google.com/uc?id={file_id}'\n",
    "        os.makedirs(os.path.dirname(output), exist_ok=True)\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        print(f\"Downloaded: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "def unpack_tar_gz(filename: str, path: str = DATA_PATH) -> None:\n",
    "    \"\"\"Rozpakowuje archiwum tar.gz do wskazanego katalogu.\"\"\"\n",
    "    with tarfile.open(filename, \"r:gz\") as tar:\n",
    "        tar.extractall(path=path)\n",
    "\n",
    "unpack_tar_gz(\"data/FashionMNIST.tar.gz\", os.path.join(DATA_PATH, \"FashionMNIST\"))\n",
    "unpack_tar_gz(\"data/FilteredFashionMNIST.tar.gz\", os.path.join(DATA_PATH, \"FilteredFashionMNIST\"))\n",
    "\n",
    "transform_fashion = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.2860,), (0.3530,))\n",
    "    ])\n",
    "\n",
    "def get_data_dict():\n",
    "    def create_filtered_loader(classes):\n",
    "        dataset = FilteredFashionMNIST(\n",
    "            root=DATA_PATH,\n",
    "            download=True,\n",
    "            transform=transform_fashion,\n",
    "            classes=classes)\n",
    "        loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True)\n",
    "        return loader\n",
    "\n",
    "    loader_fashion = DataLoader(\n",
    "        dataset=datasets.FashionMNIST(\n",
    "            root=DATA_PATH,\n",
    "            download=True,\n",
    "            transform=transform_fashion),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    class_groups = {}\n",
    "    num_classes = 10\n",
    "    for i in range(num_classes):\n",
    "        class_groups[f\"{i}\"] = [i]\n",
    "        class_groups[f\"~{i}\"] = [j for j in range(num_classes) if j != i]\n",
    "\n",
    "    data_dict = {\n",
    "        \"fashion\": {\n",
    "            \"loader\": loader_fashion,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for group_name, classes in class_groups.items():\n",
    "        loader = create_filtered_loader(classes)\n",
    "        data_dict[\"fashion\"][f\"loader_{group_name}\"] = loader\n",
    "    return data_dict\n",
    "\n",
    "data_dict = get_data_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        latent_dim = 256\n",
    "        self.fc = nn.Linear(latent_dim, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://live.staticflickr.com/65535/54549285793_e078de98d3_b.jpg\" style=\"height: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Źródło: GeeksForGeeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ładowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = LeNet(num_classes=10)\n",
    "initial_state_dict = torch.load(\"./models/lenet_base_final.pt\")\n",
    "pretrained_model.load_state_dict(initial_state_dict)\n",
    "pretrained_model = pretrained_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metryki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "def evaluate_target(model, data_loader, criterion, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Funkcja ocenia wydajność modelu na danych docelowych.\n",
    "    \n",
    "    :param model: Model PyTorch, który chcemy ocenić.\n",
    "    :param data_loader: DataLoader zawierający dane do oceny dokładności klasyfikacji.\n",
    "    :param criterion: Funkcja kosztu używana do obliczenia straty.\n",
    "    :param device: Urządzenie, na którym wykonywane są obliczenia (domyślnie \"cpu\").\n",
    "    :return: Krotka zawierająca średnią stratę oraz dokładność na danych docelowych.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return total_loss / len(data_loader.dataset), correct / len(data_loader.dataset)\n",
    "\n",
    "def measure_target_uniformity(model, loader_target, device=\"cpu\", num_classes=10):\n",
    "    \"\"\"\n",
    "    Mierzy, jak bliskie są predykcje modelu dla klasy docelowej do rozkładu jednostajnego.\n",
    "    Używamy dywergencji KL: KL(U || p(x)) lub KL(p(x) || U) jako miary jednostajności.\n",
    "\n",
    "    Obliczamy średnią KL(p || U) = sum_{y} p(y) log [p(y) / (1/num_classes)].\n",
    "    Niższa wartość KL oznacza większą jednostajność.\n",
    "    Dokładne wytłumaczenie poniżej w informacjach uzupełniających.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    kl_sum = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader_target:\n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            log_probs = F.log_softmax(logits, dim=1)\n",
    "            probs = torch.exp(log_probs)\n",
    "            entropy_term = (probs * log_probs).sum(dim=1)\n",
    "            kl_batch = entropy_term + torch.log(\n",
    "                torch.tensor(num_classes, device=device)\n",
    "            )\n",
    "            kl_sum += kl_batch.sum().item()\n",
    "            total_samples += images.size(0)\n",
    "\n",
    "    return kl_sum / total_samples\n",
    "    \n",
    "def measure_l2_distance(model, initial_state_dict, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Mierzy odległość L_2 pomiędzy aktualnym stanem modelu a jego początkowym stanem.\n",
    "    \"\"\"\n",
    "    l2_distance = 0.0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            initial_param = initial_state_dict[name]\n",
    "            l2_distance += torch.sum((param.to(device) - initial_param.to(device)) ** 2).item()\n",
    "    return l2_distance ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "WEIGHTS = [0.25, 0.25, 0.25, 0.25]\n",
    "\n",
    "acc_forget_thresholds = [0.09, 0.3]\n",
    "acc_other_thresholds = [0.87, 0.90]\n",
    "dist_thresholds = [1.3, 3.0]\n",
    "d_kl_thresholds = [0.2, 0.5]\n",
    "\n",
    "acc_forget_absolute_threshold = 0.5\n",
    "acc_target_absolute_threshold = 0.75\n",
    "distance_absolute_threshold = 8.0\n",
    "dkl_absolute_threshold = 1.75\n",
    "\n",
    "def compute_final_score(\n",
    "        kl_after, acc_rest_after, l2_dist, acc_target_after\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Funkcja oblicza końcowy wynik na podstawie różnych metryk.\n",
    "    :param kl_after: Wartość KL po treningu.\n",
    "    :param acc_rest_after: Dokładność na danych ze zbioru, który model ma pamiętać.\n",
    "    :param l2_dist: Odległość L2 po treningu.\n",
    "    :param acc_target_after: Dokładność na danych ze zbioru, który model ma zapomnieć.\n",
    "    :return: Końcowy wynik.\"\"\"\n",
    "\n",
    "    def compute_metric_score(value, thresholds, maximize=True):\n",
    "        if maximize:\n",
    "            if value >= thresholds[1]:\n",
    "                return 100\n",
    "            elif value <= thresholds[0]:\n",
    "                return 0\n",
    "            else:\n",
    "                return 100 * (value - thresholds[0]) / (thresholds[1] - thresholds[0])\n",
    "        else:\n",
    "            if value <= thresholds[0]:\n",
    "                return 100\n",
    "            elif value >= thresholds[1]:\n",
    "                return 0\n",
    "            else:\n",
    "                return 100 * (thresholds[1] - value) / (thresholds[1] - thresholds[0])\n",
    "    print(f\"Dywergencja KL: {kl_after:.2f}\")\n",
    "    print(f\"Dokładność klasyfikacji na pozostałym zbiorze: {acc_rest_after:.2f}\")\n",
    "    print(f\"Odległość L2: {l2_dist:.2f}\")\n",
    "    print(f\"Dokładność na zbiorze do zapomnienia: {acc_target_after:.2f}\")\n",
    "\n",
    "    if acc_rest_after < acc_target_absolute_threshold or acc_target_after > acc_forget_absolute_threshold \\\n",
    "            or l2_dist > distance_absolute_threshold or kl_after > dkl_absolute_threshold:\n",
    "        return 0\n",
    "\n",
    "    kl_score = compute_metric_score(kl_after, d_kl_thresholds, maximize=False)\n",
    "    acc_rest_score = compute_metric_score(acc_rest_after, acc_other_thresholds, maximize=True)\n",
    "    l2_dist_score = compute_metric_score(l2_dist, dist_thresholds, maximize=False)\n",
    "    acc_target_score = compute_metric_score(acc_target_after, acc_forget_thresholds, maximize=False)\n",
    "\n",
    "    total_score = (\n",
    "        WEIGHTS[0] * kl_score +\n",
    "        WEIGHTS[1] * acc_rest_score +\n",
    "        WEIGHTS[2] * l2_dist_score +\n",
    "        WEIGHTS[3] * acc_target_score\n",
    "    )\n",
    "\n",
    "    return total_score\n",
    "    \n",
    "def evaluate_model(model, data_loader_target, data_loader_rest, initial_state_dict, device):\n",
    "    \"\"\"\n",
    "    Funkcja ocenia model na danych docelowych i pozostałych, sprawdza odległość L2\n",
    "    oraz podobieństwo do rozkładu jednostajnego.\n",
    "    :param model: model do oceny.\n",
    "    :param data_loader_target: DataLoader dla danych docelowych.\n",
    "    :param data_loader_rest: DataLoader dla pozostałych danych.\n",
    "    :param initial_state_dict: początkowy stan modelu.\n",
    "    :param criterion: funkcja kosztu.\n",
    "    :param device: urządzenie do obliczeń.\n",
    "    :return: ocena modelu.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    _, acc_rest = evaluate_target(model, data_loader_rest, criterion, device)\n",
    "    _, acc_target = evaluate_target(model, data_loader_target, criterion, device)\n",
    "    l2_dist = measure_l2_distance(model, initial_state_dict, device)\n",
    "    kl = measure_target_uniformity(model, data_loader_target, device, num_classes=10)\n",
    "    return compute_final_score(kl, acc_rest, l2_dist, acc_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zgodność"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "def has_same_last_layer(model1: LeNet, model2: LeNet) -> bool:\n",
    "    return all(torch.equal(p1, p2) for p1, p2 in zip(model1.fc2.parameters(), model2.fc2.parameters()))\n",
    "\n",
    "def has_same_architecture(model: LeNet) -> bool:\n",
    "    return set([k for (k, v) in list(model.named_parameters())]) == \\\n",
    "        {'block1.0.weight', 'block1.0.bias', 'block1.1.weight', 'block1.1.bias', \\\n",
    "         'block2.0.weight', 'block2.0.bias', 'block2.1.weight', 'block2.1.bias', \\\n",
    "         'fc.weight', 'fc.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trywialne rozwiązanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumb_solution(model, data, target_class):\n",
    "    \"\"\"\n",
    "    Funkcja, która dodaje szum do wag modelu, aby zmienić jego zachowanie na danych docelowych.\n",
    "    :param model: Model PyTorch, który chcemy zmodyfikować.\n",
    "    :param data: Dane, na których chcemy zmodyfikować model.\n",
    "    :param target_class: Klasa docelowa, na której chcemy zmodyfikować model.\n",
    "    \"\"\"\n",
    "    new_model = deepcopy(model)  # Tworzymy kopię modelu, aby nie modyfikować oryginału\n",
    "    with torch.no_grad():\n",
    "        for name, param in new_model.named_parameters():\n",
    "            if \"fc2\" not in name:  # Ostatnia wartstwa pozostaje niezmieniona\n",
    "                param.add_(torch.randn_like(param) * 0.1)  # Dodawanie szumu do wag\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trywialne rozwiązanie - ewaluacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FINAL_EVALUATION_MODE:\n",
    "    perturbed_model = dumb_solution(pretrained_model, None, None)\n",
    "    assert has_same_last_layer(pretrained_model, perturbed_model), \"Ostatnia warstwa modelu nie jest taka sama jak w oryginalnym modelu.\"\n",
    "    assert has_same_architecture(perturbed_model), \"Architektura modelu nie jest taka sama jak w oryginalnym modelu.\"\n",
    "\n",
    "    target_class = 9\n",
    "    print(f\"Klasa docelowa: {target_class}\")\n",
    "    target_loader = data_dict[\"fashion\"][f\"loader_{target_class}\"]\n",
    "    other_loader = data_dict[\"fashion\"][f\"loader_~{target_class}\"]\n",
    "\n",
    "    score = evaluate_model(perturbed_model, target_loader, other_loader, initial_state_dict, DEVICE)\n",
    "    print(f\"Wynik: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informacje uzupełniające"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wyjaśnienie dywergencji Kullbacka-Leiblera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dywergencja Kullacka-Leiblera (ang. *Kullback-Leibler divergence*), KL, to miara rozbieżności między dwoma rozkładami prawdopodobieństwa. W kontekście uczenia maszynowego i statystyki, Dywergencja KL pozwala ocenić, jak bardzo jeden rozkład różni się od drugiego. Formalnie, dla dwóch dyskretnych rozkładów $P$ i $Q$, jest ona zdefiniowana jako:\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\parallel Q) = \\sum_{x \\in X} P(x) \\log \\frac{P(x)}{Q(x)}\n",
    "$$\n",
    "\n",
    "Gdzie:\n",
    "- $P(x)$ to prawdziwy rozkład (np. dane rzeczywiste),\n",
    "- $Q(x)$ to aproksymowany rozkład (np. predykcja modelu),\n",
    "- $X$ to przestrzeń zdarzeń.\n",
    "\n",
    "Dywergencja KL nie jest miarą symetryczną, co oznacza, że $D_{KL}(P \\parallel Q) \\neq D_{KL}(Q \\parallel P)$. Wartość dywergencji wynosi 0, gdy oba rozkłady są identyczne.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Przykłady porównań rozkładów dyskretnych:\n",
    "\n",
    "1. **Przykład 1: Identyczne rozkłady**\n",
    "    - $P = [0.4, 0.6]$\n",
    "    - $Q = [0.4, 0.6]$\n",
    "    - $D_{KL}(P \\parallel Q) = 0$\n",
    "\n",
    "2. **Przykład 2: Rozkłady różniące się nieznacznie**\n",
    "    - $P = [0.4, 0.6]$\n",
    "    - $Q = [0.5, 0.5]$\n",
    "    - $D_{KL}(P \\parallel Q) \\approx 0.02$\n",
    "\n",
    "3. **Przykład 3: Rozkłady bardzo różne**\n",
    "    - $P = [0.9, 0.1]$\n",
    "    - $Q = [0.1, 0.9]$\n",
    "    - $D_{KL}(P \\parallel Q) \\approx 0.75$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wizualizacja KL Dywergencji\n",
    "\n",
    "Poniżej znajduje się kod w Pythonie, który wizualizuje KL dywergencję dla dwóch dyskretnych rozkładów.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "     \"\"\"Oblicza KL dywergencję między dwoma rozkładami.\"\"\"\n",
    "     p = np.array(p)\n",
    "     q = np.array(q)\n",
    "     return np.sum(p * np.log(p / q))\n",
    "\n",
    "# Przykładowe rozkłady\n",
    "P = [0.4, 0.6]\n",
    "Q_list = [\n",
    "     [0.4, 0.6],  # Identyczny rozkład\n",
    "     [0.5, 0.5],  # Nieznacznie różny\n",
    "     [0.9, 0.1]   # Bardzo różny\n",
    "]\n",
    "\n",
    "# Obliczanie KL dywergencji\n",
    "kl_values = [kl_divergence(P, Q) for Q in Q_list]\n",
    "\n",
    "# Wizualizacja\n",
    "labels = ['Q1 (identyczny)', 'Q2 (nieznacznie różny)', 'Q3 (bardzo różny)']\n",
    "x = np.arange(len(Q_list))\n",
    "\n",
    "plt.bar(x, kl_values, color='skyblue')\n",
    "plt.xticks(x, labels, rotation=15)\n",
    "plt.ylabel('KL Dywergencja')\n",
    "plt.title('KL Dywergencja dla różnych rozkładów Q względem P')\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Interpretacja\n",
    "\n",
    "- Gdy $P$ i $Q$ są identyczne, KL dywergencja wynosi 0.\n",
    "- Gdy $Q$ różni się od $P$, KL dywergencja rośnie.\n",
    "- KL dywergencja nie jest symetryczna, więc zmiana kolejności $P$ i $Q$ zmienia wynik. Warto o tym pamiętać przy interpretacji wyników.\n",
    "- Możesz dostrzec różnicę między wzorem z tego zadania, a wzorem z funkcji *measure_target_uniformity()*. Wynika to z faktu, że zestawiamy nasz rozkład prawdopodobieństwa z rozkładem jednostajnym, a wówczas wzór przekształca się do tamtej postaci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pliki zgłoszeniowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Od Ciebie będziemy potrzebować zaledwie tego notebooka - wraz z kluczową definicją metodą *unlearn*, która pozwoli znaleźć ostateczne wagi modelu, na których będzie wykonana ewaluacja na wybranej przez nas klasie ze zbioru Fashion MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ograniczenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaproponowaliśmy takie wytyczne, które wymuszają niską skuteczność modelu na klasie docelowej. Pamiętaj, że w ogólnym przypadku celem naszego algorytmu oduczania powinno być osiągnięcie stanu, w którym model zachowuje się tak, jakby dane z klasy docelowej nigdy nie były częścią zbioru treningowego.\n",
    "\n",
    "Dodatkowo zakazujemy modyfikacji hiperparametrów architektury, a także jakichkolwiek parametrów warstwy klasyfikującej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oczekujemy, aby Twoje rozwiązanie opierało się i wykorzystywało jedynie standardowe biblioteki używane w uczeniu maszynowym, takie jak torch, numpy, matplotlib/seaborn, scikit-learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twoje rozwiązanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlearn(model, data, target_class):\n",
    "    \"\"\"\n",
    "    Funkcja, która wykonuje operację \"unlearn\" na modelu.\n",
    "    :param model: Model, który chcemy zmodyfikować.\n",
    "    :param data: Dane, na których chcemy zmodyfikować model, zawierające\n",
    "                 pełen zbiór danych.\n",
    "    :param target_class: Indeks klasy docelowej, którą chcemy oduczyć model.\n",
    "    return: Zmodyfikowany model.\n",
    "    \"\"\"\n",
    "    # tutaj zaproponuj swoje rozwiązanie\n",
    "    # ... \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    def prepare_data(data_dict, target_class):\n",
    "        \"\"\"\n",
    "        Przygotowuje dane do treningu modelu.\n",
    "        :param data_dict: Słownik z danymi.\n",
    "        :param target_class: Klasa docelowa.\n",
    "        :return: Krotka z danymi do zapomnienia i pozostałymi danymi.\n",
    "        \"\"\"\n",
    "        target_data = data_dict[\"fashion\"][f\"loader_{target_class}\"]\n",
    "        other_data = data_dict[\"fashion\"][f\"loader_~{target_class}\"]\n",
    "        return target_data, other_data\n",
    "    \n",
    "    target_class = 9\n",
    "    unlearned_model = unlearn(pretrained_model, data_dict, target_class)\n",
    "    target_loader, other_loader = prepare_data(data_dict, target_class)  \n",
    "    score = evaluate_model(unlearned_model, target_loader, other_loader, initial_state_dict, DEVICE)\n",
    "    print(f\"Ocena modelu po oduczaniu: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "\n",
    "if FINAL_EVALUATION_MODE:\n",
    "    import cloudpickle\n",
    "\n",
    "    OUTPUT_PATH = \"file_output\"\n",
    "    FUNCTION_FILENAME = \"your_model.pkl\"\n",
    "    FUNCTION_OUTPUT_PATH = os.path.join(OUTPUT_PATH, FUNCTION_FILENAME)\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "    with open(FUNCTION_OUTPUT_PATH, \"wb\") as f:\n",
    "        cloudpickle.dump(unlearn, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "official_olimpAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
